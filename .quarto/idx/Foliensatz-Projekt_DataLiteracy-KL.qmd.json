{"title":"Projekt: Data Literacy","markdown":{"headingText":"Herzlich Willkommen :heart_eyes:","containsRefs":false,"markdown":"```{r}\n#| include: false\nlibrary(mosaic)\n\nset.seed(1896)\ntheme.fom <- theme_classic(22*1.04)\ntheme.fom <- theme.fom\ntheme_set(\n  theme.fom  \n)\n```\n\n\n<!-- Wichtig!!! Einmalig im Verzeichnis vorher im Terminal laufen lassen! -->\n\n<!-- Dazu ins Verzeichnis Folien wechseln! -->\n\n<!-- quarto install extension quarto-ext/fontawesome -->\n\n<!-- quarto install extension jmbuhr/quarto-qrcode -->\n\n<!-- quarto add coatless/quarto-webr  -->\n\nMeine W√ºnsche f√ºr diese Veranstaltung :pray:\n\n-   :video_camera: Schalten Sie Ihre Kamera ein.\n\n-   :computer: Arbeiten Sie aktiv mit.\n\n-   :raising_hand: Stellen Sie Fragen.\n\n-   :muscle: <https://tweedback.de/xxxx/>\n\n::: center\n{{< qrcode https://tweedback.de/xxxx/quiz width=400 height=400 >}}\n:::\n\n# Grundlagen Unsicherheit\n\n## Einf√ºhrung\n\n::: incremental\n-   Ich habe hier eine M√ºnze, die ich gleich werfen werde: Wie hoch ist die Wahrscheinlichkeit f√ºr *Kopf*?\n\n-   Nachdem ich sie geworfen habe: Wie hoch ist die Wahrscheinlichkeit f√ºr *Kopf* jetzt?\n\n-   Ich habe drei verschiedene M√ºnzen, eine normale mit zwei Seiten, eine *Kopf*, die andere *Zahl*. Ich habe aber auch eine mit zwei Seiten *Kopf* und eine mit zwei Seiten *Zahl*. :scream:\n:::\n\n## Erste Lernergebnisse :woman_teacher:\n\n-   Es gibt zwei verschiedene Quellen der Unsicherheit: Zufall und Unwissenheit.\n\n-   Bevor ich die M√ºnze warf *Zufall*, nachdem ich die M√ºnze warf Ihre *Unwissenheit*. :stuck_out_tongue_winking_eye:\n\n-   Ihre erste Antwort (*50-50*) basierte auf Annahmen, z.¬†B., dass ich eine faire M√ºnze werfe. Diese k√∂nnen zutreffen, m√ºssen es aber nicht. :pray:\n\n-   Wahrscheinlichkeit als Ma√ü f√ºr Unsicherheit ist subjektiv. :fearful:\n\n::: footnote\nQuelle: Spiegelhalter D. (2024). Why probability probably doesn't exist (but it is useful to act like it does). *Nature*, *636*(8043), 560‚Äì563. <https://doi.org/10.1038/d41586-024-04096-5>\n:::\n\n## Zwei Wahrscheinlichkeiten\n\n-   **Aleatorische Wahrscheinlichkeit**: Gibt die langfristige relative H√§ufigkeit eines wiederholbaren Ereignisses an. Unter der Annahme, die Wahrscheinlichkeit f√ºr *Kopf* bei einem M√ºnzwurf ist $\\pi$, wie oft beobachte ich dann *Kopf* bei $n$ W√ºrfen?\n\n-   **Epistemische Wahrscheinlichkeit**: Gibt die relative Plausibilit√§t eines Ereignisses an. Welchen Wert hat die Wahrscheinlichkeit f√ºr *Kopf*, $\\pi$?\n\n::: footnote\nSelbst $\\pi=0.5$ bei einer fairen M√ºnze scheint nicht zu stimmen -- zumindest wenn man wei√ü, welche Seite beim Werfen oben war. Siehe Barto≈°, F., Sarafoglou, A., Godmann, H. R., Sahrani, A., Leunk, D. K., Gui, P. Y., ... & Wagenmakers, E. J. (2023). Fair coins tend to land on the same side they started: Evidence from 350,757 flips. *arXiv:2310.04153*. <https://doi.org/10.48550/arXiv.2310.04153>\n:::\n\n## Hinweis Wahrscheinlichkeiten\n\nF√ºr Wahrscheinlichkeiten gilt:\n\n-   Absolute Sicherheit, dass eine Aussage $H$ stimmt, bedeutet eine Wahrscheinlichkeit von 1: $Pr(H)=1$.\n\n-   Absolute Sicherheit, dass eine Aussage $H$ nicht stimmt, bedeutet eine Wahrscheinlichkeit von 0: $Pr(H)=0$.\n\n-   Es gilt $0 \\leq Pr(H) \\leq 1$ und $Pr(H) + Pr(\\text{nicht }H)=1$.\n\n::: footnote\n$Pr(\\cdot)$ vom englischen *Pr*obability.\n:::\n\n## Eine √úbersicht\n\n![](img/Grafiken/Schema_D2.png){height=\"800px\" fig-align=\"center\"}\n\n# Organisatorisches\n\n## √úber mich :nerd_face:\n\n-   Prof. Dr. rer.nat. Karsten L√ºbke (m), seit 2009 an der FOM Dortmund\n\n-   Wie John Tukey sagte:\n\n> The best thing about being a statistician is that you get to play in everyone's backyard.\n\n-   :email: [karsten.luebke\\@fom.de](mailto:karsten.luebke@fom.de)\n-   :iphone: 0179-2385318\n\n## Workload\n\n-   Pr√§senzstunden: 8 UE\n\n-   Virtuelle Unterrichtseinheiten: 28 UE\n\n-   Strukturiertes Eigenstudium: 50 ZStd\n\n-   Student Consulting/Praxistransfer: 40 ZStd\n\n-   Workload gesamt: **125 ZStd**\n\n-   ECTS-Credit Punkte: 5\n\n::: callout-note\n## Hinweis\n\nDie weiteren Betreuungsunterrichtseinheiten (Academic Mentoring) erfolgen √ºber Sprechstunden (Zoom, Email, Telefon) sowie Materialien in Moodle.\n:::\n\n## Academic Mentoring\n\nUm Ihr Lernen zu unterst√ºtzen sind im Moodle-Kurs hinterlegt:\n\n  - dieser Foliensatz\n  \n  - erg√§nzende Videos\n  \n  - erg√§nzende Quizze\n  \n  - Literatur\n  \n  - weitere Unterlagen und √úbersichten\n  \n::: callout-tip\n## Tipp\n\nNutzen Sie die eingestellten Unterlagen. Diese sind -- anders als die Ausgaben von Sprachmodellen -- genau auf diesen Kurs abgestimmt.\n:::  \n\n## Modulziel\n\nIn diesem Modul werden die im Modul Quantitative Datenanalyse erlernten Methoden in einer eigenst√§ndigen quantitativen Datenanalyse umgesetzt. Die Studierenden k√∂nnen nach erfolgreichem Abschluss des Moduls eine quantitative Datenanalyse entlang des PPDAC durchf√ºhren, also\n\n- ein zu analysierendes **P**roblem definieren (Forschungsfrage),\n- die **P**lanung der Analyse erstellen,\n- die ben√∂tigten **D**aten ggf. erheben (oder Sekund√§rdaten verwenden), managen und bereinigen,\n- die n√∂tigen **A**nalysen softwaregest√ºtzt durchf√ºhren und\n- die entsprechenden Schlussfolgerungen (**C**onclusion) ziehen.\n\n## Pr√ºfung und Benotung\n\n- gro√üe Seminararbeit\n- ca. 8 Wochen Bearbeitungszeit\n- 100% der Modulnote\n- Theorie-Praxis-Transfer: Das gew√§hlte Thema wird auf die Praxis bezogen und in einem eigenen Gliederungspunkt dargestellt (ca. 25% des Seminararbeitsumfangs).\n\nDie Seminararbeit umfasst im vorliegenden Modul die Durchf√ºhrung und entsprechende Dokumentation einer Datenanalyse. Die Datenanalyse muss transparent und reproduzierbar sein. Dazu sind die Daten und die Analysen (R Skripte, Quarto-Dokument) entsprechend mit einzureichen.\n\n::: callout-important\n## Wichtig\n\nDie Seminararbeit wird transparent und reproduzierbar in einem [Quarto](https://quarto.org/)-Dokument mit [R](https://www.r-project.org/) in [RStudio](https://posit.co/products/open-source/rstudio/) erstellt.\n:::\n\n## Ihre Aufgabe :mortar_board:\n\n<br>\n\n::: box\nF√ºhren Sie eine bayesianische Datenanalyse zu einer Fragestellung durch, die mit Hilfe eines Anteilswert beantwortet wird.\n:::\n\n<br>\n\n::: callout-note\n## Hinweis\n\nAnteilswerte sind z.¬†B. relative H√§ufigkeiten einer Auspr√§gung einer kategorialen Variable.\n:::\n\n## Fragestellungen\n\n-   Zwei Alternativen:\n\n    1.  Fragestellung aus Ihrer beruflichen Praxis\n\n    2.  Nachhaltiges Handeln\n\n::: callout-note\n## Hinweis\n\nSie m√ºssen Ihre Wahl in der Arbeit begr√ºnden.\n\nIn diesem Abschnitt kann Literatur helfen.\n\n:::\n\n## Fragestellung aus beruflicher Praxis\n\nDie Datenerhebung zur Beantwortung Ihrer Fragestellung kann mittels Beobachtung, (Kurz-)Umfrage oder durch unternehmensinterne Daten erfolgen.\n\n::: callout-important\n## Wichtig\n\nStellen Sie auf jeden Fall vorab sicher, dass Sie die Daten nutzen oder erheben d√ºrfen.\n:::\n\n## Fragestellung nachhaltiges Handeln\n\n-   √úberlegen Sie sich eine Fragestellung zum Thema nachhaltiges Handeln.\n\n-   Die Datenerhebung zur Beantwortung Ihrer Fragestellung kann mittels Beobachtung oder (Kurz-)Umfrage erfolgen.\n\n## Suchen Sie ein Thema, was SIE interessiert -- und niemandem schadet!\n\n::: center\n![](img/Grafiken/Meme_Seminar.jpg){width=60%}\n:::\n\n::: footnote\nWissenschaft darf auch Spa√ü machen - praktisch ist sie sowieso. :wink:\n:::\n\n\n## Ihre Fristen :student:\n\n-   01.11.2025: Anmeldefenster Seminararbeit √∂ffnet (s. Studienbuch).\n\n-   15.12.2025: Anmeldfrist Seminararbeit l√§uft ab.\n\n-   15.02.2026: Abgabefrist Seminararbeit.\n\n::: callout-warning\n## Warnung\n\nDie Fristen f√ºr die Anmeldung sowie die Abgabe k√∂nnen [nicht]{.red} verl√§ngert werden.\n:::\n\n## Formalien\n\n-   Gruppengr√∂√üen bis zu drei Personen sind m√∂glich. Die individuellen Beitr√§ge **m√ºssen** kenntlich gemacht werden. Die Aufgabenstellung und Gliederung sind f√ºr alle Gruppengr√∂√üen gleich. Mit steigender Gruppengr√∂√üe steigt der Umfang der Seminararbeit und die methodischen Mindestanforderungen in der Analyse.\n\n-   Es gibt eine Vorlagedatei f√ºr die Seminararbeit (`Vorlage_Seminararbeit.qmd`). Diese ist auch in dem [Posit Cloud](https://posit.cloud/) Projekt verf√ºgbar und sollte verwendet werden.\n\n-   Die Gliederung orientiert sich am [PPDAC Prozess](https://new.censusatschool.org.nz/wp-content/uploads/2021/12/data-detective-2021.pdf).\n\n-   Titel der Arbeit: *Bayesianische Datenanalyse*\n\n-   Abzugeben ist das PDF nach `Render PDF` sowie die Quarto-Datei `(qmd)` als Zip-Anhang.\n\n::: callout-warning\n## Warnung\n\nDas Nichteinhalten der formalen Rahmenbedingungen kann zur Folge haben, dass die Seminararbeit als nicht ausreichend bewertet wird.\n:::\n\n## Bewertungskriterien :woman_teacher:\n\n-   inhaltliche Korrektheit in Motivation, Argumentation und Interpretation\n\n-   methodische Angemessenheit und Umsetzung, siehe auch @sec-arbeit\n\n-   fachwissenschaftliche Ausdrucksweise\n\n-   Anspruch, Eigenst√§ndigkeit und Originalit√§t\n\n::: callout-note\n## Hinweis\n\nDie Gesamtnote muss nicht aus dem arithmetischen Mittel der Einzelnoten gebildet werden. Auch Defizite in einzelnen Kriterien k√∂nnen zu einer nicht mehr ausreichenden Gesamtbewertung f√ºhren.\n:::\n\n## Prim√§rquelle\n\n::::::: columns\n:::: {.column width=\"50%\"}\n![](img/Grafiken/Bayesrules.jpeg){height=\"800px\" fig-align=\"center\"}\n::::\n\n:::: {.column width=\"50%\"}\n-   Kapitel 1-3, 8.1, 8.3\n-   Verf√ºgbar unter: <https://www.bayesrulesbook.com/>\n::::\n:::::::\n\n## Literatur\n\n::::::: columns\n:::: {.column width=\"50%\"}\n::: center\n![](img/Grafiken/DBDA.png){height=\"500px\"}\n:::\n-   Kapitel 1-6\n::::\n\n:::: {.column width=\"50%\"}\n::: center\n![](img/Grafiken/Bayesstatistik.png){height=\"500px\"}\n:::\n\n-   Kapitel 1, 2, 5, 6, 7, 8, 10, 11\n-   Verf√ºgbar unter: <https://link.springer.com/book/10.1007/978-3-662-56782-1>\n::::\n:::::::\n\n## Anforderungen im Kontext wissenschaftlicher Arbeiten I / II üéì\n\nüéØ **Zielsetzung**\n\n-   eigenst√§ndige Auseinandersetzung mit einer klar definierten Fragestellung\n-   nachvollziehbare Argumentation und fundierte Schlussfolgerungen\n\n‚úçÔ∏è **Wissenschaftlicher Schreibstil**\n\n-   sachlich, pr√§zise, klar, neutral\\\n-   keine Umgangssprache, √úbertreibungen oder pers√∂nliche Wertungen\\\n-   Formulierungen in der ersten Person Singular oder Plural (Ich-, Wir-Form) sollten in (deutschsprachigen) wissenschaftlichen Texten m√∂glichst vermieden werden\\\n-   Argumentationen durch Quellen belegen\n\n## Anforderungen im Kontext wissenschaftlicher Arbeiten II / II üéì\n\nüóÇ **Formale Kriterien**\n\n-   einheitliches Layout (Schrift, Seitenr√§nder etc.)\\\n-   korrekte Rechtschreibung und Grammatik\\\n-   eindeutig definierte Fachgegriffe (z.¬†B. Signifikanzniveau, Hypothesen) korrekt verwenden\\\n-   √úbereinstimmung von Literaturverzeichnis und zitierter Literatur\n\nüßæ **Literaturverzeichnis**\n\n-   vollst√§ndige und konsistente Angaben\n-   alphabetisch sortiert\n\n‚ö†Ô∏è **Plagiatsvermeidung**\n\n-   Jede Quelle muss kenntlich gemacht werden!\\\n-   Auch bei Paraphrasen: Quellenangabe nicht vergessen!\n\n## Sprachmodelle\n\n-   Sie d√ºrfen Sprachmodelle f√ºr die Hausarbeit nutzen.\n\n-   Sie m√ºssen die Nutzung in der Arbeit kennzeichnen.\n\n-   Sie sollten die Ausgaben kritisch hinterfragen. :woman_teacher:\n\n\n::: {.callout-tip}\nKurs *MODERN-DAY ORACLES or BULLSHIT MACHINES? How to thrive in a ChatGPT world* von Carl T. Bergstrom von Jevin D. West (2025): <https://thebullshitmachines.com/>\n:::\n\n\n# Binomialverteilung in {{< fa brands r-project >}}\n\n## M√ºnzwurf :muscle:\n\nBeim $n=8$-maligen Werfen einer fairen M√ºnze mit $\\pi=0.5$: Welche Anzahl Kopf $y$ ist wahrscheinlicher?\n\n-   [**A**]{.green}: $4\\times$ Kopf.\n\n-   [**B**]{.green}: $8\\times$ Kopf.\n\n-   [**C**]{.green}: $4\\times$ Kopf und $8\\times$ Kopf sind gleich wahrscheinlich.\n\n-   [**D**]{.green}: Keine Aussage m√∂glich.\n\n## Wahrscheinlichkeit :muscle:\n\nUm was f√ºr eine Wahrscheinlichkeit handelt es sich bei der Anzahl Kopf $y=4$ bzw. $y=8$ beim $n=8$-maligen Werfen einer fairen M√ºnze mit $\\pi=0.5$?\n\n-   [**A**]{.green}: Aleatorische Wahrscheinlichkeit.\n\n-   [**B**]{.green}: Epistemische Wahrscheinlichkeit.\n\n-   [**C**]{.green}: Sowohl aleatorische als auch epistemische Wahrscheinlichkeit.\n\n-   [**D**]{.green}: Weder aleatorische noch epistemische Wahrscheinlichkeit.\n\n## M√ºnzwurf :coin:\n\n-   Nehmen Sie eine faire M√ºnze und werfen Sie diese acht Mal. Notieren Sie die Anzahl Kopf (Wappen).\n\n-   Tragen Sie Ihr Ergebnis ein und `senden` Sie es: <https://t1p.de/2ttag>.\n\n::: center\n<iframe src=\"https://docs.google.com/forms/d/e/1FAIpQLSdrj_EeRKJuWCn9eT6Z_NSt4Jj3w3IXqK2iRq0yN-3LJS7wPw/viewform?embedded=true\" width=\"640\" height=\"520\" frameborder=\"0\" marginheight=\"0\" marginwidth=\"0\">\n\nWird geladen‚Ä¶\n\n</iframe>\n:::\n\n## Hinweis M√ºnzwurf :woman_teacher:\n\n- Der M√ºnzwurf ist hier ein Stellvertreter f√ºr viele relevante Fragestellungen in Wissenschaft und Praxis, z.¬†B.:\n\n  - Mit welcher Wahrscheinlichkeit wirkt ein Medikament?\n  \n  - Mit welcher Wahrscheinlichkeit wird ein Produkt gekauft?\n  \n  - Mit welcher Wahrscheinlichkeit ist eine Antwort auf eine Klausurfrage richtig?\n\n- Grundlage sind unabh√§ngige Versuche mit den Auspr√§gungen *Erfolg* bzw. *Misserfolg*.\n\n- Ihre Aufgabenstellung ist es, eine vergleichbare Fragestellung mit einer dichotomen bzw. bin√§ren Variable zu beantworten. Auch wenn der M√ºnzwurf als solcher Sie vielleicht nicht so sehr interessiert, so lohnt es sich doch, sich ihn einmal anzuschauen. :mortar_board:\n\n\n\n## {{< fa brands r-project >}} & Friends\n\n- [R](https://www.r-project.org/) ist eine freie Programmiersprache f√ºr statistische Datenanalysen.\n\n- [RStudio](https://posit.co/products/open-source/rstudio/) ist eine Entwickungsumgebung f√ºr R.\n\n- [`{mosaic}`](https://cran.r-project.org/package=mosaic) ist ein Zusatzpaket f√ºr R.  Dies muss einmalig vorab √ºber `install.packages(\"mosaic\")`installiert werden.\n\n- [Quarto](https://quarto.org/) ist ein Publikationssystem, dass Text, Code und Ausgaben reproduzierbar kombiniert.\n\n::: callout-tip\n## Tipp\n\nSie k√∂nnen die n√∂tigen Programme lokal installieren oder den Cloud-Dienst <https://posit.cloud/> nutzen.\n:::\n\n## Hinweise Programmierung in R\n\n-   {{< fa brands r-project >}} unterscheidet zwischen Gro√ü- und Kleinbuchstaben.\n\n-   {{< fa brands r-project >}} verwendet den Punkt `.` als Dezimaltrennzeichen.\n\n-   Fehlende Werte werden in {{< fa brands r-project >}} durch `NA` kodiert.\n\n-   Eine Ergebniszuweisung erfolgt √ºber `<-`.\n\n-   Eine √úbergabe / Weitergabe erfolgt √ºber `|>`.\n\n-   `#` leitet einen Kommentar ein.\n\n## Ergebnis M√ºnzwurf :coin:\n\nDem R-Objekt `muenzergebnis` wird unser Ergebnis als Vektor (`c()`) zugewiesen (`<-`):\n\n```{webr-r}\n# mosaic aktivieren\nlibrary(mosaic)\n# Zuweisung\nmuenzergebnis <- c(NA)\n# Ausgabe\nmuenzergebnis\n```\n\n## Tabelle und S√§ulendiagramm\n\n`tally()` und `gf_bar()` , beide aus dem Paket `mosaic`, erstellen eine Tabelle bzw. ein S√§ulendiagramm des Ergebnisses:\n\n```{webr-r}\n# Tabelle\ntally( ~ muenzergebnis)\n# S√§ulendiagramm\ngf_bar( ~ muenzergebnis)\n```\n\n## M√ºnzwurf -- Forts. :muscle:\n\nBeim $n=8$-maligen Werfen einer fairen M√ºnze mit $\\pi=0.5$. Welche Anzahl Kopf $y$ ist wahrscheinlicher?\n\n-   [**A**]{.green}: $4\\times$ Kopf.\n\n-   [**B**]{.green}: $8\\times$ Kopf.\n\n-   [**C**]{.green}: $4\\times$ Kopf und $8\\times$ Kopf sind gleich wahrscheinlich.\n\n-   [**D**]{.green}: Keine Aussage m√∂glich.\n\n## Zweite Lernergebnisse :woman_teacher:\n\n-   Auch bei festem Wert $\\pi=0.5$ kommen aufgrund aleatorischer Unsicherheit unterschiedliche Ergebnisse f√ºr $y$ und $p=\\frac{y}{n}$ heraus.\n\n-   Der Wert der Statistik $p$ liegt h√§ufig in der N√§he des Wertes des Parameters $\\pi$. Kleinere Abweichungen sind dabei relativ h√§ufig, gr√∂√üere relativ selten.\n\n-   Wir k√∂nnen (und sollten!) Daten nutzen, um unsere Meinungen ggf. anzupassen. :pray:\n\n## S√§ulendiagramm verbessern\n\nR (√ºber `ggformula` bzw. `ggplot2`) bietet sehr viele M√∂glichkeiten z.¬†B. Beschriftungen etc. anzupassen:\n\n```{webr-r}\n# S√§ulendiagramm\ngf_bar( ~ muenzergebnis) |>\n  gf_labs(title = \"Ergebnis 8-facher M√ºnzwurf\",\n          x = \"Anzahl Kopf\",\n          y = \"H√§ufigkeit\")\n```\n\n## Vekoren in R\n\nFunktionen (und Operationen) werden auf den ganzen Vekor angewendet:\n\n```{webr-r}\n# Anteil Kopf bei je 8 Versuchen\nmuenzergebnis/8\n```\n\n## R als Taschenrechner\n\nMit R kann wie mit einem Taschenrechner gerechnet werden:\n\n```{webr-r}\n2+2\n```\n\nDie Werte und Ergebnisse k√∂nnen auch zugewiesen werden, um damit weiter zu rechnen:\n\n```{webr-r}\na <- 2\nb <- a + a\nb\n```\n\n## Zahlenfolge :muscle:\n\n`seq(from, to, by)` erzeugt einen Vektor einer Zahenfolge von `from` bis `to` mit einer Schrittweite von `by`.\n\nErzeugen Sie eine Zahlenfolge von $0$ bis $1$ mit einer Schrittweite von $0.01$. Benennen Sie das Ergebnis `vektor_pi`.\n\n```{webr-r}\n\n```\n\n## Gesamtergebnis\n\nF√ºr unsere Gruppe ergibt sich folgendes Gesamtergebnis:\n\n```{webr-r}\n# Anzahl Kopf insgesamt:\ny <- sum(muenzergebnis)\ny\n```\n\n```{webr-r}\n# Versuche insgesamt:\nn <- length(muenzergebnis) * 8\nn\n```\n\n## Modell M√ºnzwurf\n\n-   Die Zufallsvariable $Y$ misst die Anzahl der *Erfolge* bei einer festen Anzahl von $n$ Versuchen.\n\n-   Die Versuche sind unabh√§ngig voneinander.\n\n-   Jeder Versuch hat die gleiche Erfolgswahrscheinlichkeit $\\pi$.\n\n-   Wir **nehmen an**, dass beim fairen M√ºnzwurf $\\pi=0.5$ ist.\n\n::: callout-important\n## Wichtig\n\nWenn diese Voraussetzungen erf√ºllt sind, kann eine **Binomialverteilung** zur Modellierung des Ergebnisses verwendet werden.\n:::\n\n## Eine √úbersicht (Wiederholung) :muscle:\n\n::::: {columns}\n::: {.column width=\"50%\"}\nAuf welcher Ebene befindet sich unser konkretes Ergebnis $p=\\frac{y}{n}$?\n\n-   [**A**]{.green}: Auf der Ebene des Wahrscheinlichkeitsmpdells **P** (links oben).\n\n-   [**B**]{.green}: Auf der Ebene der Daten **D** (links unten).\n\n-   [**C**]{.green}: Auf der Ebene des Wahrscheinlichkeitsmodells **P'** (rechts oben).\n\n-   [**D**]{.green}: Auf der Ebene der Daten **D'** (rechts unten).\n:::\n\n::: {.column width=\"50%\"}\n![](img/Grafiken/Schema_D2.png){height=\"600px\" fig-align=\"center\"}\n:::\n:::::\n\n\n## Binomialverteilung\n\nWahrscheinlichkeitsfunktion $Y \\sim Binom(n, \\pi)$:\n\n$$f(y) = Pr(Y=y) = \\binom{n}{y} \\cdot \\pi^y \\cdot (1-\\pi)^{n-y}, \\text{ f√ºr } y \\in \\{0,1, \\ldots, n\\}$$\n\n-   $n \\in \\{0,1,2,\\ldots\\}$ und $\\pi \\in [0,1]$ bestimmt die Form der Verteilung.\n\n-   Erwartungswert (*Mittelwert* der Verteilung): $E(Y)=n \\cdot \\pi$\n\n-   Varianz: $Var(Y)=n \\cdot \\pi \\cdot (1-\\pi)$\n\n-   Die Likelihood-Funktion ist die Wahrscheinlichkeitsfunktion als Funktion von $\\pi$ bei gegebenem $y$. Diese ist maximal an der Stelle $p=\\frac{y}{n}$.\n\n-   {{< fa brands r-project >}} Befehle f√ºr Dichte-, Verteilungs- und Quantilsfunktion: `dbinom(); pbinom(); qbinom()` mit den Argumenten `size` $= n$ und `prob` $= \\pi$\n\n## Parameter Binomialverteilung\n\n::: center\n<iframe src=\"https://fomshinyapps.shinyapps.io/Binomialverteilung/\" width=\"3500\" height=\"450\" style=\"border:true;\">\n\n</iframe>\n:::\n\n- Je nach Wert des Parameters $\\pi$ (und Anzahl Versuche $n$) variiert die Wahrscheinlichkeit f√ºr die Anzahl Erfolge $y$.\n\n::: footnote\n<https://fomshinyapps.shinyapps.io/Binomialverteilung/>\n:::\n\n## Dichte Biomialverteilung in R\n\n```{webr-r}\n# Vektor f√ºr y bereitstellen\nvektor_y <- seq(from = 0, to = n, by = 1)\n# Wahrscheinlichkeitsvektor\nvektor_dichte <- dbinom(vektor_y, size = n, prob = 0.5)\n# Visualisierung\ngf_col(vektor_dichte ~ vektor_y) |>\n  gf_labs(x = \"y\", y = expression(f(y)), title = paste0(\"Binom(\", n, \", 0.5)\"))\n```\n\n\n## Likelihood\n\n::: {columns}\n:::: {.column width=\"50%\"}\n-   Wir haben aufgrund theoretischer √úberlegungen angenommen, dass $\\pi=0.5$ ist.\n\n-   In den meisten praktischen Fragestellungen kennen wir den Wert von $\\pi$ im datengenerierendem Prozess nicht.\n\n-   Je nachdem, welches $\\pi$ dem datengenerierendem Prozess zugrunde liegt, desto *mutma√ülicher* (engl.: *likely*) ist eine Anzahl von Erfolgen $y$ bei $n$ Versuchen.\n::::\n\n:::: {.column width=\"50%\"}\n![](img/Grafiken/Meme-Yoda-p_vs_pi.jpg){height=\"600px\" fig-align=\"center\"}\n::::\n:::\n## Likelihood in R\n\n```{webr-r}\n# Vektor f√ºr pi bereitstellen.\nvektor_pi <- seq(from = 0, to = 1, by = 1/1000)\n# Likelihood f√ºr unser Ergebnis bestimmen\nvektor_li <- dbinom(y, n, vektor_pi)\n# Visualisierung\ngf_line(vektor_li ~ vektor_pi) |>\n  gf_labs(x = expression(pi), y = \"Likelihood\")\n```\n\n## Maximum-Likelihood Punktsch√§tzer\n\n-   Der Maximum-Likelihood Punktsch√§tzer f√ºr den Wert des Parameters ist der Wert der Statistik der Daten:\n\n$$\n\\hat{\\pi}_{MLE}=p=\\frac{y}{n}\n$$\n\n```{webr-r}\n# pi_dach ist das Element von vektor_pi, dass dem Maximum der Likelihood entspricht\npi_dach <- vektor_pi[which.max(vektor_li)]\npi_dach\n```\n\n## Simulation Stichprobenergebnisse :muscle:\n\n√úber den Befehl `rbinom()` k√∂nnen binomialverteilte Zufallszahlen simuliert werden:\n\n```{webr-r}\n# Anzahl Kopf\nsim_a <- rbinom(100, size = n, prob = 0.5)\n# Anteil Kopf\nsim_a/n\n```\n\nVariiert bei festem $\\pi$ der Punktsch√§tzer $\\hat{\\pi}_{MLE}$?\n\n-   [**Ja**]{.green}\n\n-   [**Nein**]{.green}\n\n# Bayesianische Datenanalyse\n\n## Ihre Meinung :coffee:\n\nWas sch√§tzen Sie: Wie gro√ü ist der Anteil derjenigen, die morgens regelm√§√üig Kaffee trinken?\n\n-   **A**: 0-20%\n\n-   **B**: 21-40%\n\n-   **C**: 41-60%\n\n-   **D**: 61-80%\n\n-   **E**: 81-100%\n\n## Ihre Sicherheit :coffee:\n\nWie sicher sind Sie sich bei Ihrer Sch√§tzung des Anteils der\nKaffeetrinker:innen?\n\n-   **A**: Sehr sicher.\n\n-   **B**: Eher sicher.\n\n-   **C**: Eher unsicher.\n\n-   **D**: Sehr unsicher.\n\n## Ihre Daten :coffee:\n\nTrinken **Sie** morgens regelm√§√üig Kaffee?\n\n-   **Ja**\n\n-   **Nein**\n\n\n## :studio_microphone: Good Bayesian\n\n> One way to understand rational, scientific thinking is via ‚ÄúBayesian\n> reasoning‚Äù which estimates the statistical probability of something\n> being true and then updates that probability as new evidence appears,\n> approaching the truth without achieving absolute certainty.\n\nQuelle:\n<https://bababrinkman.bandcamp.com/track/good-bayesian-feat-mc-lars-and-mega-ran>\n\n## Bayes'sches Denken\n\n-   Seien Sie offen f√ºr neue Erkenntnisse. Wissenschaftliche\n    Erkenntnisse sind immer mit einer gewissen Unsicherheit verbunden,\n    und Vorannahmen, die absolute Gewissheit (oder Unm√∂glichkeit)\n    bedeuten, verhindern wissenschaftlichen Fortschritt. Dieser\n    Grundsatz ist Ausdruck der Bayes'schen Erkenntnistheorie und\n    verdeutlicht, dass wissenschaftliche Erkenntnisse vorl√§ufig sind und\n    dass Wissenschaftler:innen keine absoluten oder sicheren Aussagen\n    aufstellen sollten.\n\n-   Ber√ºcksichtigen Sie, was bereits bekannt ist. Bewerten Sie neue\n    Erkenntnisse im Lichte fr√ºherer Informationen. Dies unterstreicht,\n    dass wissenschaftliches Wissen nicht isoliert entsteht, sondern auf\n    fr√ºheren Informationen und Erkenntnissen aufbaut.\n\n-   Alternative Erkl√§rungen in Betracht ziehen. Betrachten Sie die\n    Erkenntnisse im Hinblick auf die Vereinbarkeit mit allen m√∂glichen\n    Ergebnissen; mit anderen Worten: Ber√ºcksichtigen Sie kontrafaktische\n    Szenarien. Dies dr√ºckt aus, was in der Bayes'schen Philosophie als\n    das einfache Prinzip der Konditionalisierung bezeichnet wird: Wenn\n    wir Erkenntnisse abw√§gen, m√ºssen wir ber√ºcksichtigen, inwieweit sie\n    die Bandbreite m√∂glicher Erkl√§rungen f√ºr die Daten unterst√ºtzt.\n\n::: footnote\n√úbersetzung aus: Rosenberg, J.M., Kubsch, M., Wagenmakers, E-J., Dogucu,\nM. Making Sense of Uncertainty in the Science Classroom. *Sci & Educ*\n**31**, 1239‚Äì1262 (2022). <https://doi.org/10.1007/s11191-022-00341-3>\n:::\n\n## Wissenschaftlicher Hintergrund der Aufgabenstellung\n\n-   Den Anteilswert $\\color{blue}\\pi$, den [Wert des Parameters]{.blue}\n    in der **(Ziel-)Population**, kennen wir nicht. Wir sind *unsicher*,\n    welchen Wert $\\color{blue}\\pi$ hat.\n\n-   Unter gewissen Bedingungen k√∂nnen wir berechnen, wie wahrscheinlich\n    ein Wert $\\color{green}p$ in der Stichprobe ist, wenn in der\n    Population $\\color{blue}\\pi$ gelten w√ºrde.\n\n-   Den Anteilswert $\\color{green}p$, den [Wert der Statistik]{.green},\n    unserer **Stichprobe** kennen wir, nachdem wir Daten erhoben haben.\n\n-   Sie aktualisieren Ihre Unsicherheit √ºber $\\color{blue}\\pi$ auf\n    Grundlage von $\\color{green}p$.\n\n## Was ist was? :muscle:\n\nWas ist $\\color{blue}\\pi$ im Kaffeebeispiel?\n\n-   **A**: Der Anteil der Kaffeetrinker:innen in der Population.\n\n-   **B**: Der Anteil der Kaffeetrinker:innen in der Stichprobe.\n\n## Bayes'sche Erkenntnis\n\n::: columns\n::: {.column width=\"50%\"}\n\n<br>\n\n-   Wenn Sie denken wir kennen $\\color{blue}\\pi$, dann irren Sie sich.\n\n<br>\n\n-   Sie irren sich auch, wenn Sie denken wir wissen nichts √ºber $\\color{blue}\\pi$.\n\n<br>\n\n-   Wir wissen, wie $\\color{green}p$ sich verteilt.\n\n<br>\n\n-   Wir nutzen dies, um unsere Unsicherheit √ºber $\\color{blue}\\pi$\n    anzupassen.\n:::\n\n::: {.column width=\"50%\"}\n::: center\n![](img/Grafiken/Meme_Sicherheit.jpg){width=\"70%\"}\n:::\n:::\n:::\n\n## Vorbemerkung\n\n-   Neben der konkreten Berechnung von Ergebnissen sind mathematische\n    Formeln und {{< fa brands r-project >}}-Code ein wertvolles\n    Hilfsmittel f√ºr eine pr√§zise Kommunikation.\n\n-   Mit {{< fa brands r-project >}}-Code k√∂nnen Sie alle Schritte Ihrer\n    Datenanalyse transparent und reproduzierbar durchf√ºhren.\n\n-   Mathematische Formeln erm√∂glichen es, komplexe Konzepte eindeutig\n    und pr√§zise auszudr√ºcken.\n\n-   Durch die Auseinandersetzung damit wachsen Sie und sch√§rfen Ihre\n    analytischen F√§higkeiten.\n\n-   Schwierigkeiten und Fehler geh√∂ren einfach zum Lernen dazu.\n\n-   Ich m√∂chte Sie motivieren, diesen Lernprozess durchzuhalten, damit Sie neue\n    Einsichten, Perspektiven und Erfahrungen gewinnen. :crossed_fingers:\n\n## Unsicherheit (Wiederholung)\n\n- Im Bayes'schen Sinne wird Wahrscheinlichkeit als der Grad unserer √úberzeugung verstanden, als Plausibilit√§t einer Aussage.\n\n- Absolute Sicherheit, dass eine Aussage $H$ stimmt, bedeutet eine Wahrscheinlichkeit von 1: $Pr(H)=1$.\n\n- Absolute Sicherheit, dass eine Aussage $H$ nicht stimmt, bedeutet eine Wahrscheinlichkeit von 0: $Pr(H)=0$.\n\n- Es gilt $0 \\leq Pr(H) \\leq 1$ und $Pr(H) + Pr(\\text{nicht }H)=1$.\n\n::: callout-tip\n## Tipp\n\nIn vielen F√§llen ist es sinnvoll, absolute Sicherheiten zu vermeiden (*Cromwell's rule*).\n:::\n\n::: footnote\n$Pr(\\cdot)$ vom englischen *Pr*obability. \n:::\n\n## Zwei Wahrscheinlichkeiten\n\n-   **Bayes Statistik**: Um auf Basis von [Statistiken]{.green} Aussagen\n    √ºber die Wahrscheinlichkeiten von [Parametern]{.blue} t√§tigen zu\n    k√∂nnen, brauchen wir zus√§tzlich eine *Priori*-Wahrscheinlichkeit\n    $Pr({\\color{blue}{\\pi}})$:\n\n$$\\overbrace{Pr({\\color{blue}{\\pi}} | {\\color{green}{y}} )}^{\\text{Epistemisch}} = Pr( {\\color{blue}{\\pi}} ) \\frac{\\overbrace{Pr({\\color{green}{y}} | {\\color{blue}{\\pi}})}^{\\text{Aleatorisch}}} {Pr({\\color{green}{y}})}$$\n\n-   **Epistemische Wahrscheinlichkeit**: Gibt die relative Plausibilit√§t\n    eines Ereignisses an. Hier die Wahrscheinlichkeit, dass im\n    datengeneriereden Prozess ${\\color{blue}{\\pi}}$ gilt, wenn die\n    Daten ${\\color{green}{y}}$ vorliegen.\n\n-   **Aleatorische Wahrscheinlichkeit**: Gibt die langfristige relative\n    H√§ufigkeit eines wiederholbaren Ereignisses an. Hier die\n    Wahrscheinlichkeit, dass die Daten ${\\color{green}{y}}$ sind,\n    wenn im datengeneriereden Prozess ${\\color{blue}{\\pi}}$ gilt. \n    Dies ist die klassisch-frequentistische Sicht.\n\n## Priori, Likelihood, Posteriori\n\n$$\\overbrace{Pr{(\\color{blue}{\\pi}} | {\\color{green}{y}})}^{\\text{Posteriori}} \\propto \\overbrace{Pr({\\color{blue}{\\pi}})}^{\\text{Priori}} \\cdot {\\overbrace{Pr({\\color{green}{y}} | {\\color{blue}{\\pi}})}^{\\text{Likelihood}}}$$\n\n-   **Priori-Verteilung** $Pr({\\color{blue}{\\pi}})$:\n    Wahrscheinlichkeitsverteilung von $\\color{blue}{\\pi}$, *bevor* wir\n    unsere Daten haben.\n\n-   **Likelihood** $Pr({\\color{green}{y}}|{\\color{blue}{\\pi}})$:\n    *Mutma√ülichkeit* von $\\color{green}{y}$ als Funktion von\n    $\\color{blue}{\\pi}$.\n\n-   **Posteriori-Verteilung** $Pr({\\color{blue}{\\pi}}|{\\color{green}{y}})$:\n    Wahrscheinlichkeitsverteilung von $\\color{blue}{\\pi}$ *nachdem* wir\n    unsere Daten ${\\color{green}{y}}$ haben.\n\n::: callout-note\n## Hinweis\n\nDie √úberlegungen der Bayes-Statistik sind universell und nicht auf\nAnteilswerte beschr√§nkt.\n:::\n\n::: footnote\n$\\propto$: proportional zu.\n:::\n\n## Beta-Binomial-Modell\n\n-   **Priori-Verteilung**: Grundlage Beta-Verteilung mit Parametern:\n    $\\alpha_{prior}, \\beta_{prior}$:\n    $$\\pi \\sim Beta(\\alpha_{prior}, \\beta_{prior})$$\n\n-   **Likelihood**: Grundlage Binomialverteilung mit Parametern $n$ und\n    $\\pi$: $$Y \\sim Binom(n, \\pi)$$\n\n-   **Posteriori-Verteilung**: Beta-Verteilung mit Parametern:\n    $\\alpha_{post}, \\beta_{post}$:\n    $$\\pi_{|(Y=y)} \\sim Beta(\\alpha_{post}, \\beta_{post})$$ mit\n    $$\\alpha_{post} = \\alpha_{prior} + y, \\quad \\beta_{post} = \\beta_{prior} + n - y$$\n\n\n## Beta-Verteilung\n\nDichtefunktion $\\pi \\sim Beta(\\alpha, \\beta)$:\n\n$$f(\\pi) \\propto \\pi^{\\alpha-1} \\cdot (1-\\pi)^{\\beta-1}, \\text{ f√ºr } \\pi \\in [0,1]$$\n\n-   $\\alpha > 0, \\beta >0$ bestimmen die Form der Verteilung.\n\n-   Erwartungswert (*Mittelwert* der Verteilung):\n    $E(\\pi)=\\frac{\\alpha}{\\alpha+\\beta}$\n\n-   Modus:\n    $Modus(\\pi)=\\frac{\\alpha-1}{\\alpha+\\beta-2}, \\text{ f√ºr } \\alpha, \\beta > 1$\n\n-   Varianz:\n    $Var(\\pi)=\\frac{\\alpha \\cdot \\beta}{(\\alpha+\\beta)^2 \\cdot (\\alpha+\\beta+1)}$\n\n-   {{< fa brands r-project >}} Befehle f√ºr Dichte-, Verteilungs- und\n    Quantilsfunktion: `dbeta(); pbeta(); qbeta()` mit den Argumenten\n    `shape1` $= \\alpha$ und `shape2` $= \\beta$\n\n## Beta-Verteilung in R\n\n```{webr-r}\n# Paket mosaic aktivieren\nlibrary(mosaic)\n# Vektor f√ºr pi unter dem Namen ppi bereitstellen\nppi <- seq(from = 0, to = 1, by = 1/1000)\n# alpha und beta spezifizieren\na <- 1\nb <- 1\n# Dichtevektor\ndppi <- dbeta(ppi, shape1 = a, shape2 = b)\n# Visualisierung \ngf_line(dppi ~ ppi) |>\n  gf_labs(x = expression(pi), y = expression(f(pi)), title = paste0(\"Beta(\", a, \", \" , b, \")\"))\n```\n\n## Binomialverteilung (Wiederholung)\n\nWahrscheinlichkeitsfunktion $Y \\sim Binom(n, \\pi)$:\n\n$$f(y) = Pr(Y=y) = \\binom{n}{y} \\cdot \\pi^y \\cdot (1-\\pi)^{n-y}, \\text{ f√ºr } y \\in \\{0,1, \\ldots, n\\}$$\n\n-   $n \\in \\{0,1,2,\\ldots\\}$ und $\\pi \\in [0,1]$ bestimmt die Form der Verteilung.\n\n-   Erwartungswert (*Mittelwert* der Verteilung): $E(Y)=n \\cdot \\pi$\n\n-   Varianz: $Var(Y)=n \\cdot \\pi \\cdot (1-\\pi)$\n\n-   Die Likelihood-Funktion ist die Wahrscheinlichkeitsfunktion als\n    Funktion von $\\pi$ bei gegebenem $y$. Diese ist maximal an der\n    Stelle $p=\\frac{y}{n}$.\n\n-   {{< fa brands r-project >}} Befehle f√ºr Dichte-, Verteilungs- und\n    Quantilsfunktion: `dbinom(); pbinom(); qbinom()` mit den Argumenten\n    `size` $= n$ und `prob` $= \\pi$; \n    \n    klassisch-frequentistischer Test und Konfidenzintervalle √ºber [`binom.test()`](https://stat.ethz.ch/R-manual/R-devel/library/stats/html/binom.test.html)\n\n## Biomialverteilung in R\n\n```{webr-r}\n# n und pi spezifizieren\nn <- 8\np <- 0.5\n# Vektor f√ºr y bereitstellen\ny <- seq(from = 0, to = n, by = 1)\n# Wahrscheinlichkeitsvektor\ndy <- dbinom(y, size = n, prob = p)\n# Visualisierung \ngf_col(dy ~ y) |>\n  gf_labs(x = \"y\", y = expression(f(y)), title = paste0(\"Binom(\", n, \", \" , p, \")\"))\n```\n\n## Likelihood-Funktion in R\n\n```{webr-r}\n# Vektor f√ºr pi unter dem Namen ppi bereitstellen\nppi <- seq(from = 0, to = 1, by = 1/1000)\n# n und y angeben\nn <- 8\ny <- 4\n# Likelihood\nlike <- dbinom(y, size = n, prob = ppi)\n# Visualisierung \ngf_line(like ~ ppi) |>\n  gf_labs(x = expression(pi), y = expression(L(pi)), title = paste0(\"Likelihood bei n=\", n, \" und y=\" , y))\n```\n\n\n## Vorhersagen f√ºr $y$\n\n::: columns\n::: {.column width=\"50%\"}\n\n- Epistemische Unsicherheit: Unsicherheit √ºber den Wert von $\\pi$. Modelliert √ºber eine Beta-Verteilung. Diese wird bestimmt √ºber die Parameter $\\alpha, \\beta$.\n\n- Aleatorische Unsicherheit: Unsicherheit √ºber den Wert von $y$. Modelliert √ºber eine Binomialverteilung. Diese wird bestimmt √ºber die Parameter $n, \\pi$.\n\n- Vorhersagen von beobachtbaren Gr√∂√üen k√∂nnen zum Modellcheck verwendet werden.\n:::\n\n::: {.column width=\"50%\"}\n::: center\n![](img/Grafiken/Meme_Vorhersage.jpg){width=\"70%\"}\n:::\n:::\n:::\n\n## (Priori) Vorhersagen f√ºr $y$ in R\n\n```{webr-r}\n# Anzahl Simulationen\nn_sim <- 10000\n# simuliere zuf√§llige Werte f√ºr pi gem√§√ü der Priori-Verteilung\nsim_pi_prior <- rbeta(n_sim, shape1 = a, shape2 = b)\n# simuliere Anzahl Erfolge y gem√§√ü der Binomialverteilung mit n und (zuf√§lligen) pi\nsim_y_prior <- rbinom(n_sim, size = n, prob = sim_pi_prior)\n# Visualisierung \ngf_bar( ~ sim_y_prior) |>\n  gf_labs(x = \"y\", y = \"H√§ufigkeit\", title = paste0(\"Beta-Binomial bei n=\", n, \" und Beta(\", a, \", \" , b, \")\"))\n```\n\n\n## Priori-Verteilung: $\\alpha_{prior}$ und $\\beta_{prior}$ :thinking:\n\n-   **Priori** $Pr({\\color{blue}{\\pi}})$:\n    Wahrscheinlichkeitsverteilung\n    $\\pi \\sim Beta(\\alpha_{prior}, \\beta_{prior})$.\n\n-   Je gr√∂√üer $\\alpha_{prior}$ im Vergleich zu $\\beta_{prior}$ ist,\n    desto gr√∂√üer ist der erwartete Anteil -- und umgekehrt.\n\n-   Je gr√∂√üer $\\alpha_{prior}+\\beta_{prior}$ desto geringer ist die\n    Streuung (f√ºr $\\alpha_{prior},\\beta_{prior}>1$). \n    \n\n-   $\\alpha_{prior}+\\beta_{prior}$ ist die *effektive Stichprobengr√∂√üe* (engl.: effective sample size, ESS) der Priori-Verteilung.\n    \n-   Bei $\\alpha_{prior}=\\beta_{prior}=1$ liegt eine Gleichverteilung f√ºr\n    $\\pi \\in [0,1]$ vor. $\\alpha_{prior}=\\beta_{prior}=0.5$ entspricht *Jeffreys‚Äô Prior*.\n    \n::: callout-tip\n## Tipp\n\nIm Zweifel eine wenig oder nicht-informative Priori-Verteilung w√§hlen.\n:::    \n\n## Was bewirkt was? :muscle:\n\nAngenommen, Sie sind sich aufgrund vorheriger Studien sehr sicher, dass $\\pi$ bei $0.9$ liegt.\nWelcher Parametrisierung entspricht dies am ehesten?\n\n-   **A**: $\\alpha_{prior}=1, \\beta_{prior}=9$\n\n-   **B**: $\\alpha_{prior}=10, \\beta_{prior}=90$\n\n-   **C**: $\\alpha_{prior}=9, \\beta_{prior}=1$\n\n-   **D**: $\\alpha_{prior}=90, \\beta_{prior}=10$\n\n## Vorraussetzungen Binomialverteilung\n\n-   Die Zufallsvariable $Y$ misst die Anzahl der Erfolge bei einer\n    festen Anzahl von $n$ Versuchen.\n\n-   Die Versuche sind unabh√§ngig voneinander.\n\n-   Jeder Versuch hat die gleiche Erfolgswahrscheinlichkeit $\\pi$.\n\n::: callout-important\n## Wichtig\n\n√úberlegen Sie, ob diese Bedingungen f√ºr Ihre Daten erf√ºllt sind. Wenn\nnicht, kann Ihre Likelihood falsch sein. :scream:\n:::\n\n::: callout-tip\n## Tipp\n\nMehr zur Analyse eines Anteilswertes finden Sie z.¬†B. hier: √áetinkaya-Rundel, M. & Hardin, J. (2024). *Introduction to Modern Statistics* (2e). <https://openintro-ims.netlify.app/inference-one-prop>\n:::\n\n## Von der Priori- zur Posteriori-Verteilung: $\\alpha_{post}$ und $\\beta_{post}$ :thinking:\n\n-   **Posteriori-Verteilung** $Pr({\\color{blue}{\\pi}}|{\\color{green}{y}})$:\n    Wahrscheinlichkeitsverteilung\n    $\\pi_{|(Y=y)} \\sim Beta(\\alpha_{post}, \\beta_{post})$ mit\n\n$$\\alpha_{post} = \\alpha_{prior} + y$$\n$$\\quad \\beta_{post} = \\beta_{prior} + n - y.$$\n\n-   Unter der Bedingung $Y \\sim Binom(n, \\pi)$.\n\n::: callout-tip\n## Tipp\n\nMit Hilfe der Posteriori-Verteilung k√∂nnen Sie Punkt- und\nIntervallsch√§tzer berechnen.\n:::\n\n## Was bewirkt was? :muscle:\n\nWas passiert, wenn Sie mehr Beobachtungen $n$ erheben?\n\n-   **A**: Die Streuung der Posteriori-Verteilung wird kleiner.\n\n-   **B**: Die Streuung der Posteriori-Verteilung wird gr√∂√üer.\n\n-   **C**: Die Streuung der Posteriori-Verteilung √§ndert sich nicht.\n\n# Aufbau Seminararbeit {#sec-arbeit}\n\n## Tauchen Sie unter die Oberfl√§che :nerd_face:\n\n::: center\n![](img/Grafiken/Meme-BaBeBi.jpg){width=40%}\n:::\n\n\n## Forschungsprozess: PPDAC\n\n::: center\n![](img/Grafiken/PPDAC.png){width=\"38%\"}\n:::\n\n::: footnote\n[Wild und Pfannkuch (1999)](https://doi.org/10.1111/j.1751-5823.1999.tb00442.x)\n:::\n\n\n## Eine wackelige Br√ºcke\n\nVom **P**roblem bis zu **C**onclusion -- fallen Sie nicht gleich zu Beginn!\n\n<br>\n\n:::: center\n<iframe src=\"https://giphy.com/embed/zQxOLmztiIWOs\" width=\"720\" height=\"525\" frameBorder=\"0\" class=\"giphy-embed\" allowFullScreen>\n\n</iframe>\n\n::: footnote\n[via GIPHY](https://giphy.com/gifs/animal-monkey-gibbon-zQxOLmztiIWOs)\n:::\n::::\n\n## Schritt: Problem\n\nFinden einer Fragestellung, die mit Hilfe eines Anteilswert beantwortet wird.\n\n::: callout-important\n## Wichtig\n\n> Finding the question is often more important than finding the answer. \n\nTukey, J. W. (1980). We Need Both Exploratory and Confirmatory. *The American Statistician*, *34*(*1*), 23‚Äì25. <https://doi.org/10.1080/00031305.1980.10482706>\n\n:::\n\n\n## Schritt: Problem - Checkliste\n\n-   Checkliste\n\n    -   Die Fragstellung kann mit Daten beantwortet werden. [:ballot_box_with_check:]{.green}\n    -   Es lohnt sich, die Fragestellung zu untersuchen. [:ballot_box_with_check:]{.green}\n    -   Die interessierende Variable ist klar definiert und kann erhoben werden. [:ballot_box_with_check:]{.green}\n    -   Die Zielpopulation ist klar definiert. [:ballot_box_with_check:]{.green}\n    -   Ggf.: Die Daten d√ºrfen genutzt werden. [:ballot_box_with_check:]{.green}\n\n## Schritt: Plan\n\n-   Operationalisieren Sie Ihre Fragestellung durch (eine) Single-Choice Frage(n) mit mindestens zwei Antwortalternativen.\n\n-   Die geplante Datenerhebung kann durch Beobachtung, (Online-)Fragebogen o.¬†√§. erfolgen.\n\n## Schritt: Plan - Checkliste\n\n-   Checkliste\n\n    -   Die interessierende Variable sowie Zielpopulation ist klar definiert, und kann und **darf** erhoben werden. [:ballot_box_with_check:]{.green}\n    -   Es ist m√∂glich, die Daten in *ausreichender* Anzahl zu erheben ($n \\geq 10$, besser $n \\geq 30$). [:ballot_box_with_check:]{.green}\n    -   Die Anonymit√§t / der Datenschutz ist gew√§hrleistet. [:ballot_box_with_check:]{.green}\n    -   Es sind keine negativen Auswirkungen oder Risiken f√ºr die Teilnehmenden zu erwarten. [:ballot_box_with_check:]{.green}\n\n::: callout-tip\n## Tipp\n\nUm Variabilit√§t in den Daten sicherzustellen, sollte der erwartete Anteil weder zu klein (z.¬†B. $<5\\,\\%$) noch zu gro√ü (z.¬†B. $>95\\,\\%$) sein.\n:::\n\n## Schritt: Data\n\n::::: columns\n::: {.column width=\"50%\"}\nF√ºr den Standardfehler, d.¬†h., die Standardabweichung der Stichprobenstatistik $p$, bei einer Binomialverteilung √ºber verschiedene Stichproben gilt: $$se_p=\\sqrt{\\frac{\\pi\\cdot(1-\\pi)}{n}}$$\n:::\n\n::: {.column width=\"50%\"}\n```{r}\nn <- 1:1000\nse01 <- sqrt((0.1*0.9)/n)\ngf_line(se01 ~ n) |>\n  gf_labs(x=\"Stichprobenumfang n\",\n          y =\"Standardfehler\",\n          title = \"Zusammenhang se und n (œÄ=0.1)\",\n          caption = \"Logarithmische Skalierung der x-Achse\") + \n  scale_x_log10()\n```\n:::\n:::::\n\n::: callout-tip\n## Tipp\n\nJe gr√∂√üer Ihr Stichprobenumfang $n$ ist, desto pr√§ziser ist Ihre Sch√§tzung. üéØ\n\nUnd desto mehr *Power* h√§tte ein Hypothesentest. :muscle:\n:::\n\n## Schritt: Data - Checkliste\n\n-   Checkliste\n\n    -   Die Datenerhebung (Ort, Zeit, Art) ist dokumentiert. [:ballot_box_with_check:]{.green}\n    -   Die Rohdaten sind dokumentiert und gesichert. [:ballot_box_with_check:]{.green}\n    -   Die Anonymit√§t / der Datenschutz ist gew√§hrleistet. [:ballot_box_with_check:]{.green}\n\n## Schritt: Analysis - Checkliste\n\n-   Checkliste\n\n    -   Alle Berechnungen und Abbildungen sind transparent. [:ballot_box_with_check:]{.green}\n    -   Ggf.: Bei Gruppenarbeiten ist transparent, wer f√ºr welche Analyse verantwortlich ist. [:ballot_box_with_check:]{.green}\n\n## Aus Daten lernen\n\n-   Das Ergebnis ist die gesamte Posteriori-Verteilung. \n\n-   Im Beta-Binomial-Modell lautet die Posteriori-Verteilung: $\\pi_{|(Y=y)} \\sim Beta(\\alpha_{post}, \\beta_{post})$ \\\nmit $\\alpha_{post} = \\alpha_{prior} + y; \\quad \\beta_{post} = \\beta_{prior} + n - y$.\n\n```{r}\n#| fig-align: \"center\"\n#| fig-height: 3.5\n# Paket mosaic aktivieren\nlibrary(mosaic)\n# Vektor f√ºr pi unter dem Namen ppi bereitstellen\nppi <- seq(from = 0, to = 1, by = 1/1000)\n# alpha und beta spezifizieren\na <- 3.5\nb <- 27.5\n# Dichtevektor\ndppi <- dbeta(ppi, shape1 = a, shape2 = b)\n\nmydata <- data.frame(\n  ppi = ppi,\n  dppi = dppi\n)\n# Visualisierung \ngf_line(dppi ~ ppi, data = mydata) |>\n  gf_labs(x = expression(pi), y = expression(f(pi)), \n          title = \"Posteriori-Verteilung\",\n          subtitle = paste0(\"Beispiel Beta(\", a, \", \" , b, \")\"))\n```\n\n## Bereichssch√§tzung\n\n```{r}\nkred <- 0.8\n\nzi <- qbeta(c((1-kred)/2, 1-(1-kred)/2), a, b)\nhi <- HDInterval::hdi(qbeta, kred, shape1 = a,  shape2=b)\n```\n\n::::: columns\n::: {.column width=\"50%\"}\n-   Aus der Posteriori-Verteilung k√∂nnen **Kredibilit√§tsintervalle** bestimmt werden.\n\n-   Hier erstreckt sich das [**H√∂chste-Dichte-`r kred*100`%**-Kredibilit√§tsintervall]{.green} von $`r round(hi[1],4)`$ bis $`r round(hi[2],4)`$.\n\n-   Das entsprechende **symmetrische** Kredibilit√§tsintervall reicht von $`r round(zi[1],4)`$ bis $`r round(zi[2],4)`$ (gestrichelt).\n:::\n\n::: {.column width=\"50%\"}\n```{r}\n#| fig-align: \"center\"\n#| out-width: \"90%\"\n\n# Visualisierung\ngf_line(dppi ~ ppi, data = mydata) |>\n  gf_labs(x = expression(pi), y = expression(f(pi)), \n          title = \"Posteriori-Verteilung\",\n          subtitle = paste0(\"Beispiel Beta(\", a, \", \" , b, \")\")) |>\n  gf_lims(x=c(0,0.5)) |>\n  gf_vline(xintercept = hi, color = \"#00998A\") |>\n  gf_vline(xintercept = zi, linetype = 2) +\n    geom_area(data = subset(mydata,  ppi >= hi[1] & ppi <= hi[2]), \n                  aes(x = ppi, y = dppi), fill = \"#00998A\", alpha = 0.2)\n```\n:::\n:::::\n\n::: callout-tip\n## Tipp\n\nDas H√∂chste-Dichte-Intervall kann z.¬†B. mit Hilfe der Funktion [`hdi()`](https://search.r-project.org/CRAN/refmans/HDInterval/html/hdi.html) aus dem Paket [`HDInterval`](https://cran.r-project.org/package=HDInterval) bestimmt werden, das symmetrische Intervall √ºber [`qbeta()`](https://stat.ethz.ch/R-manual/R-devel/library/stats/html/Beta.html).\n:::\n\n## Punktsch√§tzung\n\n```{r}\nmw <- a/(a+b) # Mittelwert\nmod <- (a-1)/(a+b-2) # Modus\nmed <- qbeta(0.5, a, b) # Median\n```\n\n::::: columns\n::: {.column width=\"50%\"}\nDie Posteriori-Verteilung kann durch ein Lagema√ü zusammengefasst werden, z.¬†B.:\n\n  -   [Modus: $`r round(mod,4)`$]{.orange}\n\n  -   [Median: $`r round(med,4)`$]{.violet}\n\n  -   [Mittelwert: $`r round(mw,4)`$]{.olive}    \n:::\n\n::: {.column width=\"50%\"}\n```{r}\n#| fig-align: \"center\"\n#| out-width: \"90%\"\n\n# Visualisierung\ngf_line(dppi ~ ppi, data = mydata) |>\n  gf_labs(x = expression(pi), y = expression(f(pi)), \n          title = \"Posteriori-Verteilung\",\n          subtitle = paste0(\"Beispiel Beta(\", a, \", \" , b, \")\")) |>\n  gf_vline(xintercept = mw, color = \"#808000\", size = 1.2) |>\n  gf_vline(xintercept = med, color = \"#DA70D6\", size = 1.2) |>\n  gf_vline(xintercept = mod, color = \"#FF8811\", size = 1.2) |>\n  gf_lims(x=c(0,0.5))\n```\n:::\n:::::\n\n::: callout-note\n## Hinweis\n\nModus, Median und Mittelwert beschreiben unterschiedliche Aspekte einer Verteilung und sind je nach Kriterium optimale Zusammenfassungen.\n:::\n\n## Schritt: Conclusion - Checkliste\n\n-   Checkliste\n\n    -   Die Ergebnisse werden klar, neutral und verst√§ndlich kommuniziert. [:ballot_box_with_check:]{.green}\n    -   Die Schlussfolgerung ist durch die Datenanalyse belegt. [:ballot_box_with_check:]{.green}\n    -   Die Limitationen der Arbeit sind aufgef√ºhrt. [:ballot_box_with_check:]{.green}\n\n::: callout-tip\n## Tipp\n\nVergleiche *ATOM*: Wasserstein, R. L., Schirm, A. L., & Lazar, N. A. (2019). Moving to a World Beyond ‚Äúp‚Äâ\\<‚Äâ0.05.‚Äù *The American Statistician*, *73*(sup1), 1‚Äì19. <https://doi.org/10.1080/00031305.2019.1583913>\n:::\n\n## Organisatorisches: Methodische Mindestanforderung\n\n-   Priori-Verteilung: Visualisierung\n\n-   Likelihood: Visualisierung, Punktsch√§tzer\n\n-   Posteriori-Verteilung: Visualisierung, Punktsch√§tzer und Kredibilit√§tsintervall\n\n::: callout-important\n## Wichtig\n\nAlle Berechnungen etc. m√ºssen transparent in `Code-Chunks` hinterlegt sein und die Ergebnisse interpretiert werden.\n:::\n\n\n## Organisatorisches: Gruppenarbeiten\n\n-   Die Aufgabenstellung und Gliederung sind f√ºr alle Gruppengr√∂√üen gleich. Mit steigender Gruppengr√∂√üe steigt der Umfang der Seminararbeit und die methodischen Mindestanforderungen in der Analyse.\n\n-   Individuelle Verantwortung und Bewertung:\n\n    -   zu zweit: Likelihood :student:, Posteriori :student:\n\n    -   zu dritt: Priori :student:, Likelihood :student:, Posteriori :student:\n\n::: callout-important\n## Wichtig\n\nDie individuelle Zuordnung erfolgt anhand der methodischen Prozessschritte innerhalb der Analyse.\n:::\n\n## Organisatorisches: Methodische Mindestanforderung Gruppenarbeiten\n\n-   **Zus√§tzliche** Mindestanforderungen:\n\n    -   Gruppenarbeit zu zweit:\n\n        -   Likelihood: Frequentistische Analyse, d.¬†h., Standardfehler, Konfidenzintervall :student:\n\n        -   Posteriori: Vorhersagesimulation und Modellcheck :student:\n\n    -   Gruppenarbeit zu dritt:\n\n        -   Priori: Kennzahlen, Vorhersagesimulation und Modellcheck :student:\n\n        -   Likelihood: Frequentistische Analyse, d.¬†h., Standardfehler, Konfidenzintervall :student:\n\n        -   Posteriori: Vorhersagesimulation und Modellcheck :student:\n\n::: callout-important\n## Wichtig\n\nDie individuellen Verantwortlichkeiten m√ºssen in der Arbeit gekennzeichnet werden.\n:::\n\n## Organisatorisches: Bonus :nerd_face:\n\n- Vergleich zweier Anteilswerte (siehe z. B. [`{bayesAB}`](https://cran.r-project.org/package=bayesAB))\n\n- Bayes-Faktoren (siehe z. B. [`{BayesFactor}`](https://cran.r-project.org/package=BayesFactor))\n\n\n- Sensitivit√§tsanalysen\n\n::: callout-note\n## Hinweis\n\nDie sind erg√§nzende **M√∂glichkeiten** f√ºr sehr gute Seminararbeiten, die Sie sich eigenst√§ndig mit Literatur erarbeiten k√∂nnen.\n:::\n\n## Ihr Projekt\n\n-   Vielleicht ist es m√∂glich, die Seminararbeit zu bestehen, ohne die konzeptionellen Hintergr√ºnde von *Sch√§tzen*, *Bayes*, den Aufbau von `R` oder das Arbeiten mit `Quarto` zu verstehen. :cold_sweat:\n\n-   Aber jetzt und sp√§ter: **SIE** profitieren davon, wenn **SIE** begreifen, *was* da *wie* und *warum* passiert. :mortar_board: :money_with_wings:\n\n-   Au√üerdem macht es mehr Spa√ü. :smile:\n\n-   Nachdenken :thinking:, Nachlesen [:books:]((https://www.bayesrulesbook.com/)) und Nachfragen :raising_hand: k√∂nnen dabei helfen. :innocent:\n\n![](img/Grafiken/T√ºren.jpg){height=\"400px\" fig-align=\"center\"}\n\n\n# Anhang\n\n## Shiny App\n\n::: center\n<iframe src=\"https://fomshinyapps.shinyapps.io/BaBeBi/\" title width=\"100%\" height=\"800\" style=\"border:none;\">\n</iframe>\n\n::: footnote\n<https://fomshinyapps.shinyapps.io/BaBeBi/>\n:::\n:::\n\n## Weitere Literatur (Auswahl)\n\n-   Wagenmakers E.-J., & Matzke, D. (2024). *Bayesian inference from the ground up: The theory of common sense*. <https://www.bayesianspectacles.org/free-course-book/>, insbesondere Kapitel 12.\n\n-   Albert, J., & Hu, J. (2019). *Probability and Bayesian modeling*. Chapman and Hall/CRC. <https://bayesball.github.io/BOOK/probability-a-measurement-of-uncertainty.html>, insbesondere Kapitel 7.\n\n-   Downey, A.B. (2022). *Think Bayes* (2e). <https://allendowney.github.io/ThinkBayes2/>, insbesondere Kapitel 4.\n\n::: center\n:pray: Bitte nennen Sie mir weitere Quellen, die Sie hilfreich finden. :pray:\n:::\n\n::: callout-warning\n## Warnung\n\nBei der Problemstellung dieser Seminararbeit sind Sprachmodelle oft fehleranf√§llig.\n:::\n\n## Backup: Diskrete Zufallsvariable $X$\n\n-   **Verteilungsfunktion**: $$F(x) = Pr(X \\leq x) = \\sum_{u \\leq x} f(u)$$ Wahrscheinlichkeit f√ºr einen Wert kleiner oder gleich $x$.\n\n-   **Wahrscheinlichkeitsfunktion**: $$f(x)=Pr(X=x)$$ Wahrscheinlichkeit f√ºr einen Wert gleich $x$.\n\n-   **Quantilsfunktion**: $$Q(p)=\\inf\\{x \\in \\mathbb{R}: p\\geq F(x)\\}$$ Kleinster Wert f√ºr $x$, so dass die Wahrscheinlichkeit f√ºr einen Wert kleiner oder gleich $x$ mindestens $p$ betr√§gt.\n\n## Backup: Stetige Zufallsvariable $X$\n\n-   **Verteilungsfunktion**: $$F(x) = Pr(X \\leq x) = \\int_{-\\infty}^x f(u)du$$ Wahrscheinlichkeit f√ºr einen Wert kleiner oder gleich $x$.\n\n-   **Dichtefunktion**: $$f(x)=F'(x), \\text{ wenn } F \\text{ differenzierbar ist}$$\n\n-   **Quantilsfunktion**: $$Q(p)=\\inf\\{x \\in \\mathbb{R}: p\\geq F(x)\\}$$ Kleinster Wert f√ºr $x$, so dass die Wahrscheinlichkeit f√ºr einen Wert kleiner oder gleich $x$ mindestens $p$ betr√§gt.\n\n## Backup: Konjugierte Priori-Verteilung\n\n- F√ºr binomialverteilte Stichprobendaten ist die Beta-Verteilung die *konjugierte* Priori-Verteilung, d.¬†h., auch die Posteriori-Verteilung ist dann eine Beta-Verteilung. Dies erm√∂glicht eine einfache Berechnung der Posteriori-Verteilung.\n\n- Die Wahl der Priori-Verteilung und der angestrebten Eigenschaften, ob diese z.¬†B. informativ oder nicht-informativ sein soll, ist eine **begr√ºndete** Entscheidung innerhalb der wissenschaftlichen Datenauswertung.\n\n::: callout-important\n## Wichtig\n\nDie Priori-Verteilung legen Sie im Schritt **P**lan fest, **bevor** Sie\neigene Daten erhoben haben.\n:::\n\n## Didaktischer Hintergrund :woman_teacher:\n\nF√ºr den didaktischen Hintergrund siehe z.¬†B.:\n\n- Albert, J. (2000). Using a Sample Survey Project to Assess the Teaching of Statistical Inference. *Journal of Statistics Education*, *8*(1). <https://doi.org/10.1080/10691898.2000.12131283>\n\n- Dogucu, M., Kazak, S., & Rosenberg, J. M. (2024). The Design and Implementation of a Bayesian Data Analysis Lesson for Pre-Service Mathematics and Science Teachers. *Journal of Statistics and Data Science Education*, *33*(2), 177‚Äì188. <https://doi.org/10.1080/26939169.2024.2362148> \n\n- Rosenberg, J.M., Kubsch, M., Wagenmakers, E-J., Dogucu, M. (2022). Making Sense of Uncertainty in the Science Classroom. *Sci & Educ*, *31*, 1239‚Äì1262. <https://doi.org/10.1007/s11191-022-00341-3>\n\n- Wang, F. (2021). Confidence Intervals of COVID-19 Vaccine Efficacy Rates. *Numeracy*, *14*(2). <https://doi.org/10.5038/1936-4660.14.2.1390>\n\n","srcMarkdownNoYaml":""},"formats":{"revealjs":{"identifier":{"display-name":"RevealJS","target-format":"revealjs","base-format":"revealjs"},"execute":{"fig-width":10,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":false,"output":true,"warning":false,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":true,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","html-math-method":"katex","slide-level":2,"to":"revealjs","from":"markdown+emoji","number-sections":true,"filters":["webr"],"toc":true,"toc-depth":1,"output-file":"Foliensatz-Projekt_DataLiteracy-KL.html"},"language":{"toc-title-document":"Inhaltsverzeichnis","toc-title-website":"Auf dieser Seite","related-formats-title":"Andere Formate","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Quelle","other-links-title":"Weitere Links","code-links-title":"Code-Links","launch-dev-container-title":"Dev Container starten","launch-binder-title":"Binder starten","article-notebook-label":"Artikel-Notizbuch","notebook-preview-download":"Notizbuch herunterladen","notebook-preview-download-src":"Quellcode herunterladen","notebook-preview-back":"Zur√ºck zum Artikel","manuscript-meca-bundle":"MECA-Archiv","section-title-abstract":"Zusammenfassung","section-title-appendices":"Anhang","section-title-footnotes":"Fu√ünoten","section-title-references":"Literatur","section-title-reuse":"Wiederverwendung","section-title-copyright":"Urheberrechte","section-title-citation":"Zitat","appendix-attribution-cite-as":"Bitte zitieren Sie diese Arbeit als:","appendix-attribution-bibtex":"Mit BibTeX zitieren:","appendix-view-license":"Lizenz Anzeigen","title-block-author-single":"Autor:in","title-block-author-plural":"Autor:innen","title-block-affiliation-single":"Zugeh√∂rigkeit","title-block-affiliation-plural":"Zugeh√∂rigkeiten","title-block-published":"Ver√∂ffentlichungsdatum","title-block-modified":"Ge√§ndert","title-block-keywords":"Schl√ºsselw√∂rter","callout-tip-title":"Tipp","callout-note-title":"Hinweis","callout-warning-title":"Warnung","callout-important-title":"Wichtig","callout-caution-title":"Vorsicht","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Gesamten Code zeigen","code-tools-hide-all-code":"Gesamten Code verbergen","code-tools-view-source":"Quellcode anzeigen","code-tools-source-code":"Quellcode","tools-share":"Share","tools-download":"Download","code-line":"Zeile","code-lines":"Zeilen","copy-button-tooltip":"In die Zwischenablage kopieren","copy-button-tooltip-success":"Kopiert","repo-action-links-edit":"Seite editieren","repo-action-links-source":"Quellcode anzeigen","repo-action-links-issue":"Problem melden","back-to-top":"Zur√ºck nach oben","search-no-results-text":"Keine Treffer","search-matching-documents-text":"Treffer","search-copy-link-title":"Link in die Suche kopieren","search-hide-matches-text":"Zus√§tzliche Treffer verbergen","search-more-match-text":"weitere Treffer in diesem Dokument","search-more-matches-text":"weitere Treffer in diesem Dokument","search-clear-button-title":"Zur√ºcksetzen","search-text-placeholder":"","search-detached-cancel-button-title":"Abbrechen","search-submit-button-title":"Abschicken","search-label":"Suchen","toggle-section":"Abschnitt umschalten","toggle-sidebar":"Seitenleiste umschalten","toggle-dark-mode":"Dunkelmodus umschalten","toggle-reader-mode":"Lesemodus umschalten","toggle-navigation":"Navigation umschalten","crossref-fig-title":"Abbildung","crossref-tbl-title":"Tabelle","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Korollar","crossref-prp-title":"Aussage","crossref-cnj-title":"Annahme","crossref-def-title":"Definition","crossref-exm-title":"Beispiel","crossref-exr-title":"√úbungsaufgabe","crossref-ch-prefix":"Kapitel","crossref-apx-prefix":"Anhang","crossref-sec-prefix":"Kapitel","crossref-eq-prefix":"Gleichung","crossref-lof-title":"Abbildungsverzeichnis","crossref-lot-title":"Tabellenverzeichnis","crossref-lol-title":"Listingverzeichnis","environment-proof-title":"Beweis","environment-remark-title":"Anmerkung","environment-solution-title":"L√∂sung","listing-page-order-by":"Sortieren nach","listing-page-order-by-default":"Voreinstellung","listing-page-order-by-date-asc":"Datum (aufsteigend)","listing-page-order-by-date-desc":"Neueste","listing-page-order-by-number-desc":"Absteigend","listing-page-order-by-number-asc":"Aufsteigend","listing-page-field-date":"Datum","listing-page-field-title":"Titel","listing-page-field-description":"Beschreibung","listing-page-field-author":"Autor:in","listing-page-field-filename":"Dateiname","listing-page-field-filemodified":"Ge√§ndert","listing-page-field-subtitle":"Untertitel","listing-page-field-readingtime":"Lesezeit","listing-page-field-wordcount":"Wortanzahl","listing-page-field-categories":"Kategorien","listing-page-minutes-compact":"{0} min","listing-page-category-all":"alle","listing-page-no-matches":"Keine Treffer","listing-page-words":"{0} W√∂rter","listing-page-filter":"Filter","draft":"Entwurf"},"metadata":{"lang":"de-DE","fig-responsive":false,"quarto-version":"1.5.57","auto-stretch":true,"title":"Projekt: Data Literacy","institute":"FOM Standort","author":"Prof. Dr. N.N","slideNumber":true,"number-depth":1,"webr":{"show-startup-message":false,"packages":["mosaic"]},"footer":"Projekt: Data Literacy","chalkboard":true,"main-font":"Arial","width":1920,"height":1200,"margin":0,"history":true,"center":false,"theme":["colors.scss","fontsstyles.scss","fom.scss"]}}},"projectFormats":["revealjs"]}