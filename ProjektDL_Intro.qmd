```{r}
#| include: false
library(mosaic)

set.seed(1896)
theme.fom <- theme_classic(22*1.04)
theme.fom <- theme.fom
theme_set(
  theme.fom  
)
```

```{webr-r}
#| context: setup
# Autor: Karsten L√ºbke
tweed2beta <- function(x = c(1,1,1,1,1)) {
  # Tweedback-Ergebnis Sch√§tzung Anteil Kaffeetrinker:innen in Parameter Beta Verteilung umrechnen
  # Input:
  # x[A:E]: Anzahl Antworten je Alternative A bis E
  
  # Gesch√§tzte Anteile (Klassenmitte)
  a <- c(10,30,50,70,90)/100
  
  mean_prior <- sum(x*a)/sum(x)
  cat(paste0("Mittelwert: ", mean_prior,"\n"))
  var_prior <- sum(x*(a-mean_prior)^2) / (sum(x)-1)
  cat(paste0("Varianz: ", var_prior,"\n"))
  
  # Siehe https://stats.stackexchange.com/questions/12232/calculating-the-parameters-of-a-beta-distribution-using-the-mean-and-variance
  alpha <- ((1-mean_prior) / var_prior - 1/mean_prior) * mean_prior^2
  beta <- alpha*(1/mean_prior - 1)
  
  # Output:
  # alpha, beta
  return(c(alpha, beta))
}
```



## Inhaltsverzeichnis

<!-- Wichtig!!! Einmalige Vorbereitung: -->
<!-- Wechseln Sie im Terminal ins Verzeichnis Folien. -->
<!-- Dort nacheinander die folgenden Befehle ausf√ºhren: -->
<!-- quarto install extension quarto-ext/fontawesome -->
<!-- quarto install extension jmbuhr/quarto-qrcode -->
<!-- quarto add coatless/quarto-webr  -->

[**1**$\quad$Grundlagen Unsicherheit](#sec-grundlagen)

[**2**$\quad$Organisatorisches](#sec-orga)

[**3**$\quad$Binomialverteilung in R](#sec-binom)

[**4**$\quad$Bayesianische Datenanalyse](#sec-bayes)

[**5**$\quad$Aufbau Seminararbeit](#sec-arbeit)

[**6**$\quad$Anhang](#sec-anhang)

## √úber mich :nerd_face:

- Prof. Dr. phil. nat. Matthias Gehrke (m), seit 2006 freiberuflich und ab 2008 hauptberuflich an der FOM Frankfurt
- 1993--2004 Gesellschafter-Gesch√§ftsf√ºhrer der CORTEX Biophysik GmbH, Leipzig
- Schwerpunkte in der Lehre: Statistik und Rechnungswesen
- Forschungsschwerpunkte: Finanzmarkt√∂konometrie, Hochschuldidaktik f√ºr Statistik
- :envelope:  [matthias.gehrke@fom.de](<mailto:matthias.gehrke@fom.de>)


## Herzlich Willkommen :heart_eyes:

Meine W√ºnsche f√ºr diese Veranstaltung :pray:

- :video_camera: Schalten Sie Ihre Kamera ein.
- :computer: Arbeiten Sie aktiv mit.
- :raising_hand: Stellen Sie Fragen.
- :muscle: <https://tweedback.de/2zdt/>

::: center
{{< qrcode https://tweedback.de/2zdt/quiz width=400 height=400 >}}
:::

## Wie ist die Stimmung heute?

::: center
![Quelle: [@pinterest](https://www.pinterest.de/pin/2744449766104840)](img/Icebreaker/MickeyMouse.jpg){width="50%"}
:::
<https://tweedback.de/2zdt/>

# Skript Teil I/II: <br>Intro, Organisatorisches, Theorie {.unnumbered}

# Grundlagen Unsicherheit {#sec-grundlagen}

## Einf√ºhrung

::: incremental
- Ich habe hier eine M√ºnze, die ich gleich werfen werde: Wie hoch ist die Wahrscheinlichkeit f√ºr *Kopf*?
- Nachdem ich sie geworfen habe: Wie hoch ist die Wahrscheinlichkeit f√ºr *Kopf* jetzt?
- Ich habe drei verschiedene M√ºnzen, eine normale mit zwei Seiten, eine *Kopf*, die andere *Zahl*. Ich habe aber auch eine mit zwei Seiten *Kopf* und eine mit zwei Seiten *Zahl*. :scream:
:::

## Erste Lernergebnisse :woman_teacher:

- Es gibt zwei verschiedene Quellen der Unsicherheit: Zufall und Unwissenheit.
- Bevor ich die M√ºnze warf *Zufall*, nachdem ich die M√ºnze warf Ihre *Unwissenheit*. :stuck_out_tongue_winking_eye:
- Ihre erste Antwort (*50-50*) basierte auf Annahmen, z.¬†B., dass ich eine faire M√ºnze werfe. Diese k√∂nnen zutreffen, m√ºssen es aber nicht. :pray:
- Wahrscheinlichkeit als Ma√ü f√ºr Unsicherheit ist subjektiv. :fearful:

::: footnote
Quelle: Spiegelhalter D. (2024). Why probability probably doesn't exist (but it is useful to act like it does). *Nature*, *636*(8043), 560‚Äì563. <https://doi.org/10.1038/d41586-024-04096-5>
:::

## Zwei Wahrscheinlichkeiten

- **Aleatorische Wahrscheinlichkeit**: Gibt die langfristige relative H√§ufigkeit eines wiederholbaren Ereignisses an. Unter der Annahme, die Wahrscheinlichkeit f√ºr *Kopf* bei einem M√ºnzwurf ist $\pi$, wie oft beobachte ich dann *Kopf* bei $n$ W√ºrfen?
- **Epistemische Wahrscheinlichkeit**: Gibt die relative Plausibilit√§t eines Ereignisses an. Welchen Wert hat die Wahrscheinlichkeit f√ºr *Kopf*, $\pi$?

::: footnote
Selbst $\pi=0.5$ bei einer fairen M√ºnze scheint nicht zu stimmen -- zumindest wenn man wei√ü, welche Seite beim Werfen oben war. Siehe Barto≈°, F., Sarafoglou, A., Godmann, H. R., Sahrani, A., Leunk, D. K., Gui, P. Y., ... & Wagenmakers, E. J. (2023). Fair coins tend to land on the same side they started: Evidence from 350,757 flips. *arXiv:2310.04153*. <https://doi.org/10.48550/arXiv.2310.04153>
:::

## Hinweis Wahrscheinlichkeiten

F√ºr Wahrscheinlichkeiten gilt:

- Absolute Sicherheit, dass eine Aussage $H$ stimmt, bedeutet eine Wahrscheinlichkeit von 1: $Pr(H)=1$.
- Absolute Sicherheit, dass eine Aussage $H$ nicht stimmt, bedeutet eine Wahrscheinlichkeit von 0: $Pr(H)=0$.
- Es gilt $0 \leq Pr(H) \leq 1$ und $Pr(H) + Pr(\text{nicht }H)=1$.

::: footnote
$Pr(\cdot)$ vom englischen *Pr*obability.
:::

## Eine √úbersicht

![](img/Grafiken/Schema_D2.png){height="800px" fig-align="center"}

# Organisatorisches {#sec-orga}

## Workload

- (Virtuelle) Pr√§senzstunden: 8 UE
- Virtuelle Unterrichtseinheiten: 28 UE
- Strukturiertes Eigenstudium: 58 ZStd
- Student Consulting/Praxistransfer: 40 ZStd
- Workload gesamt: **125 ZStd**
- ECTS-Credit Punkte: 5

::: callout-note
## Hinweis

Die virtuellen Unterrichtseinheiten (Academic Mentoring) erfolgen √ºber Sprechstunden (Zoom, Email, Telefon) sowie Materialien in Moodle.
:::

## Academic Mentoring

Um Ihr Lernen zu unterst√ºtzen sind im Moodle-Kurs hinterlegt:

- dieser Foliensatz
- erg√§nzende Videos
- erg√§nzende Quizze
- Literatur
- weitere Unterlagen und √úbersichten

::: callout-tip
## Tipp

Nutzen Sie die eingestellten Unterlagen. Diese sind -- anders als die Ausgaben von Sprachmodellen -- genau auf diesen Kurs abgestimmt.
:::

## Modulziel

In diesem Modul werden die im Modul Quantitative Datenanalyse erlernten Methoden in einer eigenst√§ndigen quantitativen Datenanalyse umgesetzt. Die Studierenden k√∂nnen nach erfolgreichem Abschluss des Moduls eine quantitative Datenanalyse entlang des PPDAC durchf√ºhren, also

- ein zu analysierendes **P**roblem definieren (Forschungsfrage),
- die **P**lanung der Analyse erstellen,
- die ben√∂tigten **D**aten ggf. erheben (oder Sekund√§rdaten verwenden), managen und bereinigen,
- die n√∂tigen **A**nalysen softwaregest√ºtzt durchf√ºhren und
- die entsprechenden Schlussfolgerungen (**C**onclusion) ziehen.

## Pr√ºfung und Benotung

- gro√üe Seminararbeit
- ca. 8 Wochen Bearbeitungszeit
- 100% der Modulnote
- Theorie-Praxis-Transfer: Das gew√§hlte Thema wird auf die Praxis bezogen und in einem eigenen Gliederungspunkt dargestellt (ca. 25% des Seminararbeitsumfangs).

Die Seminararbeit umfasst im vorliegenden Modul die Durchf√ºhrung und entsprechende Dokumentation einer Datenanalyse. Die Datenanalyse muss transparent und reproduzierbar sein. Dazu sind die Daten und die Analysen (R Skripte, Quarto-Dokument) entsprechend mit einzureichen.

::: callout-important
## Wichtig

Die Seminararbeit wird transparent und reproduzierbar in einem [Quarto](https://quarto.org/)-Dokument mit [R](https://www.r-project.org/) in [RStudio](https://posit.co/products/open-source/rstudio/) erstellt.
:::

## Ihre Aufgabe :mortar_board:

<br>

::: box
F√ºhren Sie eine bayesianische Datenanalyse zu einer Fragestellung durch, die mit Hilfe eines Anteilswert beantwortet wird.
:::

<br>

::: callout-note
## Hinweis

Anteilswerte sind z.¬†B. relative H√§ufigkeiten einer Auspr√§gung einer kategorialen Variable.
:::

## Fragestellungen

- Zwei Alternativen:

    1.  Fragestellung aus Ihrer beruflichen Praxis

    2.  Nachhaltiges Handeln

::: callout-note
## Hinweis

Sie m√ºssen die Wahl Ihrer individuellen Fragestellung in der Arbeit begr√ºnden.

In diesem Abschnitt kann Literatur helfen.
:::

## Fragestellung aus beruflicher Praxis

Die Datenerhebung zur Beantwortung Ihrer Fragestellung kann mittels Beobachtung, (Kurz-)Umfrage oder durch unternehmensinterne Daten erfolgen.

::: callout-important
## Wichtig

Stellen Sie auf jeden Fall vorab sicher, dass Sie die Daten nutzen oder erheben d√ºrfen.
:::

## Fragestellung nachhaltiges Handeln

- √úberlegen Sie sich eine Fragestellung zum Thema nachhaltiges Handeln.
- Die Datenerhebung zur Beantwortung Ihrer Fragestellung kann mittels Beobachtung oder (Kurz-)Umfrage erfolgen.

## Suchen Sie ein Thema, was SIE interessiert -- und niemandem schadet!

::: center
![](img/Grafiken/Meme_Seminar.jpg){width="60%"}
:::

::: footnote
Wissenschaft darf auch Spa√ü machen - praktisch ist sie sowieso. :wink:
:::

## Ihre Fristen :student:

- 01.11.2025: Anmeldefenster Seminararbeit √∂ffnet (s. Studienbuch).
- 15.12.2025: Anmeldefrist Seminararbeit l√§uft ab.
- 15.02.2026: Abgabefrist Seminararbeit.

::: callout-warning
## Warnung

Die Fristen f√ºr die Anmeldung sowie die Abgabe k√∂nnen [nicht]{.red} verl√§ngert werden.
:::

## Formalien

- Gruppengr√∂√üen bis zu drei Personen sind m√∂glich. Die individuellen Beitr√§ge **m√ºssen** kenntlich gemacht werden. Die Aufgabenstellung und Gliederung sind f√ºr alle Gruppengr√∂√üen gleich. Mit steigender Gruppengr√∂√üe steigt der Umfang der Seminararbeit und die methodischen Mindestanforderungen in der Analyse.
- Es gibt eine Vorlagedatei f√ºr die Seminararbeit (`Vorlage_Seminararbeit.qmd`). Diese ist auch in dem [Posit Cloud](https://posit.cloud/) Projekt verf√ºgbar und sollte verwendet werden.
- Die Gliederung orientiert sich am [PPDAC Prozess](https://new.censusatschool.org.nz/wp-content/uploads/2021/12/data-detective-2021.pdf).
- Titel der Arbeit: *Bayesianische Datenanalyse*
- Abzugeben ist das PDF nach `Render PDF`, sowei die Quarto-Datei `(qmd)` und ggf. die Daten als Zip-Anhang.

::: callout-warning
## Warnung

Das Nichteinhalten der formalen Rahmenbedingungen kann zur Folge haben, dass die Seminararbeit als nicht ausreichend bewertet wird.
:::

## Bewertungskriterien :woman_teacher:

- inhaltliche Korrektheit in Motivation, Argumentation und Interpretation
- methodische Angemessenheit und Umsetzung, siehe auch @sec-arbeit
- fachwissenschaftliche Ausdrucksweise
- Anspruch, Eigenst√§ndigkeit und Originalit√§t

::: callout-note
## Hinweis

Die Gesamtnote muss nicht aus dem arithmetischen Mittel der Einzelnoten gebildet werden. Auch Defizite in einzelnen Kriterien k√∂nnen zu einer nicht mehr ausreichenden Gesamtbewertung f√ºhren.
:::

## Prim√§rquelle

::::: columns
::: {.column width="50%"}
![](img/Grafiken/Bayesrules.jpeg){height="800px" fig-align="center"}
:::

::: {.column width="50%"}
- Kapitel 1-3, 8.1, 8.3
- Verf√ºgbar unter: <https://www.bayesrulesbook.com/>
:::
:::::

## Literatur

::::::: columns
:::: {.column width="50%"}
::: center
![](img/Grafiken/DBDA.png){height="500px"}
:::

- Kapitel 1--6
::::

:::: {.column width="50%"}
::: center
![](img/Grafiken/Bayesstatistik.png){height="500px"}
:::

- Kapitel 1, 2, 5, 6, 7, 8, 10, 11
- Verf√ºgbar unter: <https://link.springer.com/book/10.1007/978-3-662-56782-1>
::::
:::::::

## Anforderungen im Kontext wissenschaftlicher Arbeiten I / II üéì

üéØ **Zielsetzung**

- eigenst√§ndige Auseinandersetzung mit einer klar definierten Fragestellung
- nachvollziehbare Argumentation und fundierte Schlussfolgerungen

‚úçÔ∏è **Wissenschaftlicher Schreibstil**

- sachlich, pr√§zise, klar, neutral\
- keine Umgangssprache, √úbertreibungen oder pers√∂nliche Wertungen\
- Formulierungen in der ersten Person Singular oder Plural (Ich-, Wir-Form) sollten in (deutschsprachigen) wissenschaftlichen Texten m√∂glichst vermieden werden\
- Argumentationen durch Quellen belegen

## Anforderungen im Kontext wissenschaftlicher Arbeiten II / II üéì

üóÇ **Formale Kriterien**

- einheitliches Layout (Schrift, Seitenr√§nder etc.)\
- korrekte Rechtschreibung und Grammatik\
- eindeutig definierte Fachgegriffe (z.¬†B. Signifikanzniveau, Hypothesen) korrekt verwenden\
- √úbereinstimmung von Literaturverzeichnis und zitierter Literatur

üßæ **Literaturverzeichnis**

- vollst√§ndige und konsistente Angaben
- alphabetisch sortiert

‚ö†Ô∏è **Plagiatsvermeidung**

- Jede Quelle muss kenntlich gemacht werden!\
- Auch bei Paraphrasen: Quellenangabe nicht vergessen!

## Sprachmodelle

- Sie d√ºrfen Sprachmodelle f√ºr die Hausarbeit nutzen.
- Sie m√ºssen die Nutzung in der Arbeit kennzeichnen.
- Sie sollten die Ausgaben kritisch hinterfragen. :woman_teacher:

::: callout-tip
Kurs *MODERN-DAY ORACLES or BULLSHIT MACHINES? How to thrive in a ChatGPT world* von Carl T. Bergstrom von Jevin D. West (2025): <https://thebullshitmachines.com/>
:::

# Binomialverteilung in {{< fa brands r-project >}} {#sec-binom}

## M√ºnzwurf :muscle:

Beim $n=8$-maligen Werfen einer fairen M√ºnze mit $\pi=0.5$: Welche Anzahl Kopf $y$ ist wahrscheinlicher?

- [**A**]{.green}: $4\times$ Kopf.
- [**B**]{.green}: $8\times$ Kopf.
- [**C**]{.green}: $4\times$ Kopf und $8\times$ Kopf sind gleich wahrscheinlich.
- [**D**]{.green}: Keine Aussage m√∂glich.

## Wahrscheinlichkeit :muscle:

Um was f√ºr eine Wahrscheinlichkeit handelt es sich bei der Anzahl Kopf $y=4$ bzw. $y=8$ beim $n=8$-maligen Werfen einer fairen M√ºnze mit $\pi=0.5$?

- [**A**]{.green}: Aleatorische Wahrscheinlichkeit.
- [**B**]{.green}: Epistemische Wahrscheinlichkeit.
- [**C**]{.green}: Sowohl aleatorische als auch epistemische Wahrscheinlichkeit.
- [**D**]{.green}: Weder aleatorische noch epistemische Wahrscheinlichkeit.

## M√ºnzwurf <i class="fa-solid fa-coins"></i> 

- Nehmen Sie eine faire M√ºnze und werfen Sie diese acht Mal. Notieren Sie die Anzahl Kopf (Wappen).
- Tragen Sie Ihr Ergebnis bitte hier ein: <https://survey.fom.de/muenzwurf-vorlesung/>.

::: center
{{< qrcode https://survey.fom.de/muenzwurf-vorlesung/ width=400 height=400 >}}
:::

- Geben Sie dabei den [**Namen Ihrer Lehrperson**]{.green} und das [**heutige Datum**]{.green} an, damit wir unser Kursergebnis verwenden k√∂nnen. Achten Sie auf die richtige Schreibweise des Namens. 


## Hinweis M√ºnzwurf :woman_teacher:

- Der M√ºnzwurf ist hier ein Stellvertreter f√ºr viele relevante Fragestellungen in Wissenschaft und Praxis, z.¬†B.:
  - Mit welcher Wahrscheinlichkeit wirkt ein Medikament?
  - Mit welcher Wahrscheinlichkeit wird ein Produkt gekauft?
  - Mit welcher Wahrscheinlichkeit ist eine Antwort auf eine Klausurfrage richtig?
- Grundlage sind unabh√§ngige Versuche mit den Auspr√§gungen *Erfolg* bzw. *Misserfolg*.
- Ihre Aufgabenstellung ist es, eine vergleichbare Fragestellung mit einer dichotomen bzw. bin√§ren Variable zu beantworten. Auch wenn der M√ºnzwurf als solcher Sie vielleicht nicht so sehr interessiert, so lohnt es sich doch, sich ihn einmal anzuschauen. :mortar_board:

## {{< fa brands r-project >}} & Friends

- [R](https://www.r-project.org/) ist eine freie Programmiersprache f√ºr statistische Datenanalysen.
- [RStudio](https://posit.co/products/open-source/rstudio/) ist eine Entwickungsumgebung f√ºr R.
- [`mosaic`](https://cran.r-project.org/package=mosaic) ist ein Zusatzpaket f√ºr R. Dies muss einmalig vorab √ºber `install.packages("mosaic")`installiert werden.
- [Quarto](https://quarto.org/) ist ein Publikationssystem, dass Text, Code und Ausgaben reproduzierbar kombiniert.

::: callout-tip
## Tipp

Sie k√∂nnen die n√∂tigen Programme lokal installieren oder den Cloud-Dienst <https://posit.cloud/> nutzen.
:::

## Hinweise Programmierung in R

- {{< fa brands r-project >}} unterscheidet zwischen Gro√ü- und Kleinbuchstaben.
- {{< fa brands r-project >}} verwendet den Punkt `.` als Dezimaltrennzeichen.
- Fehlende Werte werden in {{< fa brands r-project >}} durch `NA` kodiert.
- Eine Ergebniszuweisung erfolgt √ºber `<-`.
- Eine √úbergabe / Weitergabe erfolgt √ºber `|>`.
- `#` leitet einen Kommentar ein.

## Ergebnis M√ºnzwurf <i class="fa-solid fa-coins"></i>

Dem R-Objekt `muenzergebnis` wird unser Ergebnis als Vektor (`c()`) zugewiesen (`<-`):

```{webr-r}
# mosaic aktivieren
library(mosaic)
# Zuweisung
muenzergebnis <- c(NA)
# Ausgabe
muenzergebnis
```

::: fragment
<br>
Das Ergebnis k√∂nnen Sie z. B. mit `length(...)` oder `mean(...)` √ºberpr√ºfen.
Probieren Sie es aus, es sollten alle dasselbe Ergebnis bekommen.
:::

## Tabelle und S√§ulendiagramm

`tally()` und `gf_bar()` , beide aus dem Paket `mosaic`, erstellen eine Tabelle bzw. ein S√§ulendiagramm des Ergebnisses:

```{webr-r}
# Tabelle
tally( ~ muenzergebnis)
# S√§ulendiagramm
gf_bar( ~ muenzergebnis)
```

## M√ºnzwurf -- Forts. :muscle:

Beim $n=8$-maligen Werfen einer fairen M√ºnze mit $\pi=0.5$. Welche Anzahl Kopf $y$ ist wahrscheinlicher?

- [**A**]{.green}: $4\times$ Kopf.
- [**B**]{.green}: $8\times$ Kopf.
- [**C**]{.green}: $4\times$ Kopf und $8\times$ Kopf sind gleich wahrscheinlich.
- [**D**]{.green}: Keine Aussage m√∂glich.

## Zweite Lernergebnisse :woman_teacher:

- Auch bei festem Wert $\pi=0.5$ kommen aufgrund aleatorischer Unsicherheit unterschiedliche Ergebnisse f√ºr $y$ und $p=\frac{y}{n}$ heraus.
- Der Wert der Statistik $p$ liegt h√§ufig in der N√§he des Wertes des Parameters $\pi$. Kleinere Abweichungen sind dabei relativ h√§ufig, gr√∂√üere relativ selten.
- Wir k√∂nnen (und sollten!) Daten nutzen, um unsere Meinungen ggf. anzupassen. :pray:

## S√§ulendiagramm verbessern

R (√ºber `ggformula` bzw. `ggplot2`) bietet sehr viele M√∂glichkeiten z.¬†B. Beschriftungen etc. anzupassen:

```{webr-r}
# S√§ulendiagramm
gf_bar( ~ muenzergebnis) |>
  gf_labs(title = "Ergebnis 8-facher M√ºnzwurf",
          x = "Anzahl Kopf",
          y = "H√§ufigkeit")
```

## Vekoren in R

Funktionen (und Operationen) werden auf den ganzen Vekor angewendet:

```{webr-r}
# Anteil Kopf bei je 8 Versuchen
muenzergebnis/8
```

## R als Taschenrechner

Mit R kann wie mit einem Taschenrechner gerechnet werden:

```{webr-r}
2+2
```

Die Werte und Ergebnisse k√∂nnen auch zugewiesen werden, um damit weiter zu rechnen:

```{webr-r}
a <- 2
b <- a + a
b
```

## Zahlenfolge :muscle:

`seq(from, to, by)` erzeugt einen Vektor einer Zahlenfolge von `from` bis `to` mit einer Schrittweite von `by`.

Erzeugen Sie eine Zahlenfolge von $0$ bis $1$ mit einer Schrittweite von $0.01$. Benennen Sie das Ergebnis `vektor_pi`.

```{webr-r}

```

## Gesamtergebnis

F√ºr unsere Gruppe ergibt sich folgendes Gesamtergebnis:

```{webr-r}
# Anzahl Kopf insgesamt:
y <- sum(muenzergebnis)
y
```

```{webr-r}
# Versuche insgesamt:
n <- length(muenzergebnis) * 8
n
```

## Modell M√ºnzwurf

- Die Zufallsvariable $Y$ misst die Anzahl der *Erfolge* bei einer festen Anzahl von $n$ Versuchen.
- Die Versuche sind unabh√§ngig voneinander.
- Jeder Versuch hat die gleiche Erfolgswahrscheinlichkeit $\pi$.
- Wir **nehmen an**, dass beim fairen M√ºnzwurf $\pi=0.5$ ist.

::: callout-important
## Wichtig

Wenn diese Voraussetzungen erf√ºllt sind, kann eine **Binomialverteilung** zur Modellierung des Ergebnisses verwendet werden.
:::

## Eine √úbersicht (Wiederholung) :muscle:

::::: {columns}
::: {.column width="50%"}
Auf welcher Ebene befindet sich unser konkretes Ergebnis $p=\frac{y}{n}$?

- [**A**]{.green}: Auf der Ebene des Wahrscheinlichkeitsmodells **P** (links oben).
- [**B**]{.green}: Auf der Ebene der Daten **D** (links unten).
- [**C**]{.green}: Auf der Ebene des Wahrscheinlichkeitsmodells **P'** (rechts oben).
- [**D**]{.green}: Auf der Ebene der Daten **D'** (rechts unten).
:::

::: {.column width="50%"}
![](img/Grafiken/Schema_D2.png){height="600px" fig-align="center"}
:::
:::::

## Binomialverteilung

Wahrscheinlichkeitsfunktion $Y \sim Binom(n, \pi)$:

$$f(y) = Pr(Y=y) = \binom{n}{y} \cdot \pi^y \cdot (1-\pi)^{n-y}, \text{ f√ºr } y \in \{0,1, \ldots, n\}$$

- $n \in \{0,1,2,\ldots\}$ und $\pi \in [0,1]$ bestimmt die Form der Verteilung.
- Erwartungswert (*Mittelwert* der Verteilung): $E(Y)=n \cdot \pi$
- Varianz: $Var(Y)=n \cdot \pi \cdot (1-\pi)$
- Die Likelihood-Funktion ist die Wahrscheinlichkeitsfunktion als Funktion von $\pi$ bei gegebenem $y$. Diese ist maximal an der Stelle $p=\frac{y}{n}$.
- {{< fa brands r-project >}} Befehle f√ºr Dichte-, Verteilungs- und Quantilsfunktion: `dbinom(); pbinom(); qbinom()` mit den Argumenten `size` $= n$ und `prob` $= \pi$

## Parameter Binomialverteilung

::: center
<iframe src="https://fomshinyapps.shinyapps.io/Binomialverteilung/" width="3500" height="450" style="border:true;">

</iframe>
:::

- Je nach Wert des Parameters $\pi$ (und Anzahl Versuche $n$) variiert die Wahrscheinlichkeit f√ºr die Anzahl Erfolge $y$.

::: footnote
<https://fomshinyapps.shinyapps.io/Binomialverteilung/>
:::

## Dichte Biomialverteilung in R

```{webr-r}
# Vektor f√ºr y bereitstellen
vektor_y <- seq(from = 0, to = n, by = 1)
# Wahrscheinlichkeitsvektor
vektor_dichte <- dbinom(vektor_y, size = n, prob = 0.5)
# Visualisierung
gf_col(vektor_dichte ~ vektor_y) |>
  gf_labs(x = "y", y = expression(f(y)), title = paste0("Binom(", n, ", 0.5)"))
```

## Likelihood

::::: {columns}
::: {.column width="50%"}
- Wir haben aufgrund theoretischer √úberlegungen angenommen, dass $\pi=0.5$ ist.
- In den meisten praktischen Fragestellungen kennen wir den Wert von $\pi$ im datengenerierendem Prozess nicht.
- Je nachdem, welches $\pi$ dem datengenerierendem Prozess zugrunde liegt, desto *mutma√ülicher* (engl.: *likely*) ist eine Anzahl von Erfolgen $y$ bei $n$ Versuchen.
:::

::: {.column width="50%"}
![](img/Grafiken/Meme-Yoda-p_vs_pi.jpg){height="600px" fig-align="center"}
:::
:::::

## Likelihood in R

```{webr-r}
# Vektor f√ºr pi bereitstellen.
vektor_pi <- seq(from = 0, to = 1, by = 1/1000)
# Likelihood f√ºr unser Ergebnis bestimmen
vektor_li <- dbinom(y, n, vektor_pi)
# Visualisierung
gf_line(vektor_li ~ vektor_pi) |>
  gf_labs(x = expression(pi), y = "Likelihood")
```

## Maximum-Likelihood Punktsch√§tzer

- Der Maximum-Likelihood Punktsch√§tzer f√ºr den Wert des Parameters ist der Wert der Statistik der Daten:

$$
\hat{\pi}_{MLE}=p=\frac{y}{n}
$$

```{webr-r}
# pi_dach ist das Element von vektor_pi, dass dem Maximum der Likelihood entspricht
pi_dach <- vektor_pi[which.max(vektor_li)]
pi_dach
```

## Simulation Stichprobenergebnisse :muscle:

√úber den Befehl `rbinom()` k√∂nnen binomialverteilte Zufallszahlen simuliert werden:

```{webr-r}
# Anzahl Kopf
sim_a <- rbinom(100, size = n, prob = 0.5)
# Anteil Kopf
sim_a/n
```

Variiert bei festem $\pi$ der Punktsch√§tzer $\hat{\pi}_{MLE}$?

- [**Ja**]{.green}
- [**Nein**]{.green}

# Bayesianische Datenanalyse {#sec-bayes}

## Ihre Meinung :coffee:

Was sch√§tzen Sie: Wie gro√ü ist der Anteil derjenigen, die morgens regelm√§√üig Kaffee trinken?

- [**A**:]{.green} 0-20%
- [**B**:]{.green} 21-40%
- [**C**:]{.green} 41-60%
- [**D**:]{.green} 61-80%
- [**E**:]{.green} 81-100%

## Ihre Sicherheit :coffee:

Wie sicher sind Sie sich bei Ihrer Sch√§tzung des Anteils der Kaffeetrinker:innen?

- [**A**:]{.green} Sehr sicher.
- [**B**:]{.green} Eher sicher.
- [**C**:]{.green} Eher unsicher.
- [**D**:]{.green} Sehr unsicher.

## Ihre Daten :coffee:

Trinken **Sie** morgens regelm√§√üig Kaffee?

- [**Ja**]{.green}
- [**Nein**]{.green}

## :studio_microphone: Good Bayesian

> One way to understand rational, scientific thinking is via ‚ÄúBayesian reasoning‚Äù which estimates the statistical probability of something being true and then updates that probability as new evidence appears, approaching the truth without achieving absolute certainty.

Quelle: <https://bababrinkman.bandcamp.com/track/good-bayesian-feat-mc-lars-and-mega-ran>

## Bayes'sches Denken

- Seien Sie offen f√ºr neue Erkenntnisse. Wissenschaftliche Erkenntnisse sind immer mit einer gewissen Unsicherheit verbunden, und Vorannahmen, die absolute Gewissheit (oder Unm√∂glichkeit) bedeuten, verhindern wissenschaftlichen Fortschritt. Dieser Grundsatz ist Ausdruck der Bayes'schen Erkenntnistheorie und verdeutlicht, dass wissenschaftliche Erkenntnisse vorl√§ufig sind und dass Wissenschaftler:innen keine absoluten oder sicheren Aussagen aufstellen sollten.
- Ber√ºcksichtigen Sie, was bereits bekannt ist. Bewerten Sie neue Erkenntnisse im Lichte fr√ºherer Informationen. Dies unterstreicht, dass wissenschaftliches Wissen nicht isoliert entsteht, sondern auf fr√ºheren Informationen und Erkenntnissen aufbaut.
- Alternative Erkl√§rungen in Betracht ziehen. Betrachten Sie die Erkenntnisse im Hinblick auf die Vereinbarkeit mit allen m√∂glichen Ergebnissen; mit anderen Worten: Ber√ºcksichtigen Sie kontrafaktische Szenarien. Dies dr√ºckt aus, was in der Bayes'schen Philosophie als das einfache Prinzip der Konditionalisierung bezeichnet wird: Wenn wir Erkenntnisse abw√§gen, m√ºssen wir ber√ºcksichtigen, inwieweit sie die Bandbreite m√∂glicher Erkl√§rungen f√ºr die Daten unterst√ºtzt.

::: footnote
√úbersetzung aus: Rosenberg, J.M., Kubsch, M., Wagenmakers, E-J., Dogucu, M. Making Sense of Uncertainty in the Science Classroom. *Sci & Educ* **31**, 1239‚Äì1262 (2022). <https://doi.org/10.1007/s11191-022-00341-3>
:::

## Wissenschaftlicher Hintergrund der Aufgabenstellung

- Den Anteilswert $\color{blue}\pi$, den [Wert des Parameters]{.blue} in der **(Ziel-)Population**, kennen wir nicht. Wir sind *unsicher*, welchen Wert $\color{blue}\pi$ hat.
- Unter gewissen Bedingungen k√∂nnen wir berechnen, wie wahrscheinlich ein Wert $\color{green}p$ in der Stichprobe ist, wenn in der Population $\color{blue}\pi$ gelten w√ºrde.
- Den Anteilswert $\color{green}p$, den [Wert der Statistik]{.green}, unserer **Stichprobe** kennen wir, nachdem wir Daten erhoben haben.
- Sie aktualisieren Ihre Unsicherheit √ºber $\color{blue}\pi$ auf Grundlage von $\color{green}p$.

## Was ist was? :muscle:

Was ist $\color{blue}\pi$ im Kaffeebeispiel?

- [**A**:]{.green} Der Anteil der Kaffeetrinker:innen in der Population.
- [**B**:]{.green} Der Anteil der Kaffeetrinker:innen in der Stichprobe.

## Bayes'sche Erkenntnis

:::::: columns
::: {.column width="50%"}
<br>

- Wenn Sie denken wir kennen $\color{blue}\pi$, dann irren Sie sich.

<br>

- Sie irren sich auch, wenn Sie denken wir wissen nichts √ºber $\color{blue}\pi$.

<br>

- Wir wissen, wie $\color{green}p$ sich verteilt.

<br>

- Wir nutzen dies, um unsere Unsicherheit √ºber $\color{blue}\pi$ anzupassen.
:::

:::: {.column width="50%"}
::: center
![](img/Grafiken/Meme_Sicherheit.jpg){width="70%"}
:::
::::
::::::

## Vorbemerkung

- Neben der konkreten Berechnung von Ergebnissen sind mathematische Formeln und {{< fa brands r-project >}}-Code ein wertvolles Hilfsmittel f√ºr eine pr√§zise Kommunikation.
- Mit {{< fa brands r-project >}}-Code k√∂nnen Sie alle Schritte Ihrer Datenanalyse transparent und reproduzierbar durchf√ºhren.
- Mathematische Formeln erm√∂glichen es, komplexe Konzepte eindeutig und pr√§zise auszudr√ºcken.
- Durch die Auseinandersetzung damit wachsen Sie und sch√§rfen Ihre analytischen F√§higkeiten.
- Schwierigkeiten und Fehler geh√∂ren einfach zum Lernen dazu.
- Ich m√∂chte Sie motivieren, diesen Lernprozess durchzuhalten, damit Sie neue Einsichten, Perspektiven und Erfahrungen gewinnen. :crossed_fingers:

## Unsicherheit (Wiederholung)

- Im Bayes'schen Sinne wird Wahrscheinlichkeit als der Grad unserer √úberzeugung verstanden, als Plausibilit√§t einer Aussage.
- Absolute Sicherheit, dass eine Aussage $H$ stimmt, bedeutet eine Wahrscheinlichkeit von 1: $Pr(H)=1$.
- Absolute Sicherheit, dass eine Aussage $H$ nicht stimmt, bedeutet eine Wahrscheinlichkeit von 0: $Pr(H)=0$.
- Es gilt $0 \leq Pr(H) \leq 1$ und $Pr(H) + Pr(\text{nicht }H)=1$.

::: callout-tip
## Tipp

In vielen F√§llen ist es sinnvoll, absolute Sicherheiten zu vermeiden (*Cromwell's rule*).
:::

::: footnote
$Pr(\cdot)$ vom englischen *Pr*obability.
:::

## Zwei Wahrscheinlichkeiten

- **Bayes Statistik**: Um auf Basis von [Statistiken]{.green} Aussagen √ºber die Wahrscheinlichkeiten von [Parametern]{.blue} t√§tigen zu k√∂nnen, brauchen wir zus√§tzlich eine *Priori*-Wahrscheinlichkeit $Pr({\color{blue}{\pi}})$:

$$\overbrace{Pr({\color{blue}{\pi}} | {\color{green}{y}} )}^{\text{Epistemisch}} = Pr( {\color{blue}{\pi}} ) \frac{\overbrace{Pr({\color{green}{y}} | {\color{blue}{\pi}})}^{\text{Aleatorisch}}} {Pr({\color{green}{y}})}$$

- **Epistemische Wahrscheinlichkeit**: Gibt die relative Plausibilit√§t eines Ereignisses an. Hier die Wahrscheinlichkeit, dass im datengeneriereden Prozess ${\color{blue}{\pi}}$ gilt, wenn die Daten ${\color{green}{y}}$ vorliegen.
- **Aleatorische Wahrscheinlichkeit**: Gibt die langfristige relative H√§ufigkeit eines wiederholbaren Ereignisses an. Hier die Wahrscheinlichkeit, dass die Daten ${\color{green}{y}}$ sind, wenn im datengeneriereden Prozess ${\color{blue}{\pi}}$ gilt. Dies ist die klassisch-frequentistische Sicht.

## Priori, Likelihood, Posteriori

$$\overbrace{Pr{(\color{blue}{\pi}} | {\color{green}{y}})}^{\text{Posteriori}} \propto \overbrace{Pr({\color{blue}{\pi}})}^{\text{Priori}} \cdot {\overbrace{Pr({\color{green}{y}} | {\color{blue}{\pi}})}^{\text{Likelihood}}}$$

- **Priori-Verteilung** $Pr({\color{blue}{\pi}})$: Wahrscheinlichkeitsverteilung von $\color{blue}{\pi}$, *bevor* wir unsere Daten haben.
- **Likelihood** $Pr({\color{green}{y}}|{\color{blue}{\pi}})$: *Mutma√ülichkeit* von $\color{green}{y}$ als Funktion von $\color{blue}{\pi}$.
- **Posteriori-Verteilung** $Pr({\color{blue}{\pi}}|{\color{green}{y}})$: Wahrscheinlichkeitsverteilung von $\color{blue}{\pi}$, *nachdem* wir unsere Daten ${\color{green}{y}}$ haben.

::: callout-note
## Hinweis

Die √úberlegungen der Bayes-Statistik sind universell und nicht auf Anteilswerte beschr√§nkt.
:::

::: footnote
$\propto$: proportional zu.
:::

## Beta-Binomial-Modell

- **Priori-Verteilung**: Grundlage Beta-Verteilung mit Parametern: $\alpha_{prior}, \beta_{prior}$: $$\pi \sim Beta(\alpha_{prior}, \beta_{prior})$$
- **Likelihood**: Grundlage Binomialverteilung mit Parametern $n$ und $\pi$: $$Y \sim Binom(n, \pi)$$
- **Posteriori-Verteilung**: Beta-Verteilung mit Parametern: $\alpha_{post}, \beta_{post}$: $$\pi_{|(Y=y)} \sim Beta(\alpha_{post}, \beta_{post})$$ mit $$\alpha_{post} = \alpha_{prior} + y, \quad \beta_{post} = \beta_{prior} + n - y$$

## Beta-Verteilung

Dichtefunktion $\pi \sim Beta(\alpha, \beta)$:

$$f(\pi) \propto \pi^{\alpha-1} \cdot (1-\pi)^{\beta-1}, \text{ f√ºr } \pi \in [0,1]$$

- $\alpha > 0, \beta >0$ bestimmen die Form der Verteilung.
- Erwartungswert (*Mittelwert* der Verteilung): $E(\pi)=\frac{\alpha}{\alpha+\beta}$
- Modus: $Modus(\pi)=\frac{\alpha-1}{\alpha+\beta-2}, \text{ f√ºr } \alpha, \beta > 1$
- Varianz: $Var(\pi)=\frac{\alpha \cdot \beta}{(\alpha+\beta)^2 \cdot (\alpha+\beta+1)}$
- {{< fa brands r-project >}} Befehle f√ºr Dichte-, Verteilungs- und Quantilsfunktion: `dbeta(); pbeta(); qbeta()` mit den Argumenten `shape1` $= \alpha$ und `shape2` $= \beta$

## Beta-Verteilung in R

```{webr-r}
# Vektor f√ºr pi unter dem Namen ppi bereitstellen
ppi <- seq(from = 0, to = 1, by = 1/1000)
# alpha und beta spezifizieren
a <- 1
b <- 1
# Dichtevektor
dppi <- dbeta(ppi, shape1 = a, shape2 = b)
# Visualisierung 
gf_line(dppi ~ ppi) |>
  gf_labs(x = expression(pi), y = expression(f(pi)), title = paste0("Beta(", a, ", " , b, ")"))
```

## Priori-Verteilung in R

```{webr-r}
# Aus dem Ergebnis der Umfrage alpha und beta ermitteln
# Hinweis: eigene Funktion, mehr dazu sp√§ter
# Hier die Ergebnisse des Kurses eintragen, um Mittelwert, Varianz sowie Alpha und Beta zu erhalten: 
tweed2beta(c(1,1,1,1,1))
# alpha und beta spezifizieren
a <- 1
b <- 1
# Dichtevektor
dppi <- dbeta(ppi, shape1 = a, shape2 = b)
# Visualisierung 
gf_line(dppi ~ ppi) |>
  gf_labs(x = expression(pi), y = expression(f(pi)), title = paste0("Beta(", a, ", " , b, ")"))
```

## Shiny App

::: center
<iframe src="https://fomshinyapps.shinyapps.io/BaBeBi/" title width="90%" height="750" style="border:none;">

</iframe>

::: footnote
<https://fomshinyapps.shinyapps.io/BaBeBi/>
:::
:::


## Binomialverteilung (Wiederholung)

Wahrscheinlichkeitsfunktion $Y \sim Binom(n, \pi)$:

$$f(y) = Pr(Y=y) = \binom{n}{y} \cdot \pi^y \cdot (1-\pi)^{n-y}, \text{ f√ºr } y \in \{0,1, \ldots, n\}$$

- $n \in \{0,1,2,\ldots\}$ und $\pi \in [0,1]$ bestimmt die Form der Verteilung.
- Erwartungswert (*Mittelwert* der Verteilung): $E(Y)=n \cdot \pi$
- Varianz: $Var(Y)=n \cdot \pi \cdot (1-\pi)$
- Die Likelihood-Funktion ist die Wahrscheinlichkeitsfunktion als Funktion von $\pi$ bei gegebenem $y$. Diese ist maximal an der Stelle $p=\frac{y}{n}$.
- {{< fa brands r-project >}} Befehle f√ºr Dichte-, Verteilungs- und Quantilsfunktion: `dbinom(); pbinom(); qbinom()` mit den Argumenten `size` $= n$ und `prob` $= \pi$;

    klassisch-frequentistischer Test und Konfidenzintervalle √ºber [`binom.test()`](https://stat.ethz.ch/R-manual/R-devel/library/stats/html/binom.test.html)

## Biomialverteilung in R

```{webr-r}
# n und pi spezifizieren
n <- 8
p <- 0.5
# Vektor f√ºr y bereitstellen
y <- seq(from = 0, to = n, by = 1)
# Wahrscheinlichkeitsvektor
dy <- dbinom(y, size = n, prob = p)
# Visualisierung 
gf_col(dy ~ y) |>
  gf_labs(x = "y", y = expression(f(y)), title = paste0("Binom(", n, ", " , p, ")"))
```

## Likelihood-Funktion in R

```{webr-r}
# Vektor f√ºr pi unter dem Namen ppi bereitstellen
ppi <- seq(from = 0, to = 1, by = 1/1000)
# n und y angeben
n <- 8
y <- 4
# Likelihood
like <- dbinom(y, size = n, prob = ppi)
# Visualisierung 
gf_line(like ~ ppi) |>
  gf_labs(x = expression(pi), y = expression(L(pi)), title = paste0("Likelihood bei n=", n, " und y=" , y))
```

## Vorhersagen f√ºr $y$

:::::: columns
::: {.column width="50%"}
- Epistemische Unsicherheit: Unsicherheit √ºber den Wert von $\pi$. Modelliert √ºber eine Beta-Verteilung. Diese wird bestimmt √ºber die Parameter $\alpha, \beta$.
- Aleatorische Unsicherheit: Unsicherheit √ºber den Wert von $y$. Modelliert √ºber eine Binomialverteilung. Diese wird bestimmt √ºber die Parameter $n, \pi$.
- Vorhersagen von beobachtbaren Gr√∂√üen k√∂nnen zum Modellcheck verwendet werden.
:::

:::: {.column width="50%"}
::: center
![](img/Grafiken/Meme_Vorhersage.jpg){width="70%"}
:::
::::
::::::

## (Priori) Vorhersagen f√ºr $y$ in R

```{webr-r}
# Anzahl Simulationen
n_sim <- 10000
# simuliere zuf√§llige Werte f√ºr pi gem√§√ü der Priori-Verteilung
sim_pi_prior <- rbeta(n_sim, shape1 = a, shape2 = b)
# simuliere Anzahl Erfolge y gem√§√ü der Binomialverteilung mit n und (zuf√§lligen) pi
sim_y_prior <- rbinom(n_sim, size = n, prob = sim_pi_prior)
# Visualisierung 
gf_bar( ~ sim_y_prior) |>
  gf_labs(x = "y", y = "H√§ufigkeit", title = paste0("Beta-Binomial bei n=", n, " und Beta(", a, ", " , b, ")"))
```

## Priori-Verteilung: $\alpha_{prior}$ und $\beta_{prior}$ :thinking:

- **Priori** $Pr({\color{blue}{\pi}})$: Wahrscheinlichkeitsverteilung $\pi \sim Beta(\alpha_{prior}, \beta_{prior})$.
- Je gr√∂√üer $\alpha_{prior}$ im Vergleich zu $\beta_{prior}$ ist, desto gr√∂√üer ist der erwartete Anteil -- und umgekehrt.
- Je gr√∂√üer $\alpha_{prior}+\beta_{prior}$ desto geringer ist die Streuung (f√ºr $\alpha_{prior},\beta_{prior}>1$).
- $\alpha_{prior}+\beta_{prior}$ ist die *effektive Stichprobengr√∂√üe* (engl.: effective sample size, ESS) der Priori-Verteilung.
- Bei $\alpha_{prior}=\beta_{prior}=1$ liegt eine Gleichverteilung f√ºr $\pi \in [0,1]$ vor. $\alpha_{prior}=\beta_{prior}=0.5$ entspricht *Jeffreys‚Äô Prior*.

::: callout-tip
## Tipp

Im Zweifel eine wenig oder nicht-informative Priori-Verteilung w√§hlen.
:::

## Was bewirkt was? :muscle:

Angenommen, Sie sind sich aufgrund vorheriger Studien sehr sicher, dass $\pi$ bei $0.9$ liegt. Welcher Parametrisierung entspricht dies am ehesten?

- [**A**:]{.green} $\alpha_{prior}=1, \beta_{prior}=9$
- [**B**:]{.green} $\alpha_{prior}=10, \beta_{prior}=90$
- [**C**:]{.green} $\alpha_{prior}=9, \beta_{prior}=1$
- [**D**:]{.green} $\alpha_{prior}=90, \beta_{prior}=10$

## Vorraussetzungen Binomialverteilung

- Die Zufallsvariable $Y$ misst die Anzahl der Erfolge bei einer festen Anzahl von $n$ Versuchen.
- Die Versuche sind unabh√§ngig voneinander.
- Jeder Versuch hat die gleiche Erfolgswahrscheinlichkeit $\pi$.

::: callout-important
## Wichtig

√úberlegen Sie, ob diese Bedingungen f√ºr Ihre Daten erf√ºllt sind. Wenn nicht, kann Ihre Likelihood falsch sein. :scream:
:::

::: callout-tip
## Tipp

Mehr zur Analyse eines Anteilswertes finden Sie z.¬†B. hier: √áetinkaya-Rundel, M. & Hardin, J. (2024). *Introduction to Modern Statistics* (2e). <https://openintro-ims.netlify.app/inference-one-prop>
:::

## Von der Priori- zur Posteriori-Verteilung: $\alpha_{post}$ und $\beta_{post}$ :thinking:

- **Posteriori-Verteilung** $Pr({\color{blue}{\pi}}|{\color{green}{y}})$: Wahrscheinlichkeitsverteilung $\pi_{|(Y=y)} \sim Beta(\alpha_{post}, \beta_{post})$ mit

$$\alpha_{post} = \alpha_{prior} + y$$ $$\quad \beta_{post} = \beta_{prior} + n - y.$$

- Unter der Bedingung $Y \sim Binom(n, \pi)$.

::: callout-tip
## Tipp

Mit Hilfe der Posteriori-Verteilung k√∂nnen Sie Punkt- und Intervallsch√§tzer berechnen.
:::

## Was bewirkt was? :muscle:

Was passiert, wenn Sie mehr Beobachtungen $n$ erheben?

- [**A**:]{.green} Die Streuung der Posteriori-Verteilung wird kleiner.
- [**B**:]{.green} Die Streuung der Posteriori-Verteilung wird gr√∂√üer.
- [**C**:]{.green} Die Streuung der Posteriori-Verteilung √§ndert sich nicht.

## Posteriori-Verteilung in R

```{webr-r}
# Vektor f√ºr pi unter dem Namen ppi bereitstellen
ppi <- seq(from = 0, to = 1, by = 1/1000)
# alpha und beta spezifizieren
a <- 1
b <- 1
# Dichtevektor
dppi <- dbeta(ppi, shape1 = a, shape2 = b)
# Visualisierung 
gf_line(dppi ~ ppi) |>
  gf_labs(x = expression(pi), y = expression(f(pi)), title = paste0("Beta(", a, ", " , b, ")"))
```

## √úbung: Priori, Likelihood, Posteriori :muscle:

Plotten Sie f√ºr das Kaffeebeispiel die Prior- und Posterior-Verteilung, sowie die Likelihood in einem Grafen, Farben orange, gr√ºn, lila.

::: footnote
*Tipp:* Mit der Pipe `|>` k√∂nnen Sie mehrere Liniengrafiken √ºbereinander legen. \
*Hinweis:* Im Code m√ºssen noch verschiedene Anpassungen vorgenommen werden.
:::
::::: columns
::: {.column width=50%}
```{webr-r}
# Vektor f√ºr pi unter dem Namen ppi bereitstellen
ppi <- seq(from = 0, to = 1, by = 1/1000)
# alphaprior und betaprior festlegen
aprior <- 1
bprior <- 1
# Dichtevektor f√ºr die Prior-Verteilung erzeugen
dprior <- dbeta(ppi, shape1 = a, shape2 = b)
# n und y der Likelihood angeben
n <- 8
y <- 4
# Likelihood erzeugen
like <- dbinom(y, size = n, prob = ppi)
# alphapost und betapost festlegen
apost <- 1
bpost <- 1
# Dichtevektor f√ºr die Posterior-Verteilung erzeugen
dpost <- dbeta(ppi, shape1 = a, shape2 = b)

```
:::
::: {.column width=50%}
```{webr-r}
# alle drei in einem Grafen ausgeben
# gf_line(...)
```
:::
:::::


# Skript Teil II/II: <br>Wiederholung, Seminararbeit {.unnumbered}

## Herzlich Willkommen :heart_eyes:

Meine W√ºnsche f√ºr diese Veranstaltung :pray:

- :video_camera: Schalten Sie Ihre Kamera ein.
- :computer: Arbeiten Sie aktiv mit.
- :raising_hand: Stellen Sie Fragen.
- :muscle: <https://tweedback.de/2usa/>

::: center
{{< qrcode https://tweedback.de/2usa/quiz width=400 height=400 >}}
:::

## Wie ist die Stimmung heute?

::: center
![Quelle: [Reddit](https://i.redd.it/acefwczsilz41.jpg)](img/Icebreaker/Halloween.jpg){width="50%"}
:::
<https://tweedback.de/2usa/>


# Wiederholung {.unnumbered}

# Aufbau Seminararbeit {#sec-arbeit}

## Tauchen Sie unter die Oberfl√§che :nerd_face:

::: center
![](img/Grafiken/Meme-BaBeBi.jpg){width="40%"}
:::

## Forschungsprozess: PPDAC

::: center
![](img/Grafiken/PPDAC.png){width="38%"}
:::

::: footnote
[Wild und Pfannkuch (1999)](https://doi.org/10.1111/j.1751-5823.1999.tb00442.x)
:::

## Eine wackelige Br√ºcke

Vom **P**roblem bis zu **C**onclusion -- fallen Sie nicht gleich zu Beginn!

<br>

:::: center
<iframe src="https://giphy.com/embed/zQxOLmztiIWOs" width="720" height="525" frameBorder="0" class="giphy-embed" allowFullScreen>

</iframe>

::: footnote
[via GIPHY](https://giphy.com/gifs/animal-monkey-gibbon-zQxOLmztiIWOs)
:::
::::

## Schritt: Problem

Finden einer Fragestellung, die mit Hilfe eines Anteilswert beantwortet wird.

::: callout-important
## Wichtig

> Finding the question is often more important than finding the answer.

Tukey, J. W. (1980). We Need Both Exploratory and Confirmatory. *The American Statistician*, *34*(*1*), 23‚Äì25. <https://doi.org/10.1080/00031305.1980.10482706>
:::

## Schritt: Problem - Checkliste

- Checkliste
  - Die Fragstellung kann mit Daten beantwortet werden. [:ballot_box_with_check:]{.green}
  - Es lohnt sich, die Fragestellung zu untersuchen. [:ballot_box_with_check:]{.green}
  - Die interessierende Variable ist klar definiert und kann erhoben werden. [:ballot_box_with_check:]{.green}
  - Die Zielpopulation ist klar definiert. [:ballot_box_with_check:]{.green}
  - Ggf.: Die Daten d√ºrfen genutzt werden. [:ballot_box_with_check:]{.green}

## Schritt: Plan

- Operationalisieren Sie Ihre Fragestellung durch (eine) Single-Choice Frage(n) mit mindestens zwei Antwortalternativen.
- Die geplante Datenerhebung kann durch Beobachtung, (Online-)Fragebogen o.¬†√§. erfolgen.

## Schritt: Plan - Checkliste

- Checkliste
  - Die interessierende Variable sowie Zielpopulation ist klar definiert, und kann und **darf** erhoben werden. [:ballot_box_with_check:]{.green}
  - Es ist m√∂glich, die Daten in *ausreichender* Anzahl zu erheben ($n \geq 10$, besser $n \geq 30$). [:ballot_box_with_check:]{.green}
  - Die Anonymit√§t / der Datenschutz ist gew√§hrleistet. [:ballot_box_with_check:]{.green}
  - Es sind keine negativen Auswirkungen oder Risiken f√ºr die Teilnehmenden zu erwarten. [:ballot_box_with_check:]{.green}

::: callout-tip
## Tipp

Um Variabilit√§t in den Daten sicherzustellen, sollte der erwartete Anteil weder zu klein (z.¬†B. <¬†5¬†%) noch zu gro√ü (z.¬†B. >¬†95¬†%) sein.
:::

## Schritt: Data

::::: columns
::: {.column width="50%"}
F√ºr den Standardfehler, d.¬†h., die Standardabweichung der Stichprobenstatistik $p$, bei einer Binomialverteilung √ºber verschiedene Stichproben gilt: $$se_p=\sqrt{\frac{\pi\cdot(1-\pi)}{n}}$$
:::

::: {.column width="50%"}
```{r}
n <- 1:1000
se01 <- sqrt((0.1*0.9)/n)
gf_line(se01 ~ n) |>
  gf_labs(x="Stichprobenumfang n",
          y ="Standardfehler",
          title = "Zusammenhang se und n (œÄ=0.1)",
          caption = "Logarithmische Skalierung der x-Achse") + 
  scale_x_log10()
```
:::
:::::

::: callout-tip
## Tipp

Je gr√∂√üer Ihr Stichprobenumfang $n$ ist, desto pr√§ziser ist Ihre Sch√§tzung. üéØ

Und desto mehr *Power* h√§tte ein Hypothesentest. :muscle:
:::

## Schritt: Data - Checkliste

- Checkliste
  - Die Datenerhebung (Ort, Zeit, Art) ist dokumentiert. [:ballot_box_with_check:]{.green}
  - Die Rohdaten sind dokumentiert und gesichert. [:ballot_box_with_check:]{.green}
  - Die Anonymit√§t / der Datenschutz ist gew√§hrleistet. [:ballot_box_with_check:]{.green}

## Schritt: Analysis - Checkliste

- Checkliste
  - Alle Berechnungen und Abbildungen sind transparent. [:ballot_box_with_check:]{.green}
  - Ggf.: Bei Gruppenarbeiten ist transparent, wer f√ºr welche Analyse verantwortlich ist. [:ballot_box_with_check:]{.green}

## Aus Daten lernen

- Das Ergebnis ist die gesamte Posteriori-Verteilung.
- Im Beta-Binomial-Modell lautet die Posteriori-Verteilung: $\pi_{|(Y=y)} \sim Beta(\alpha_{post}, \beta_{post})$\
    mit $\alpha_{post} = \alpha_{prior} + y; \quad \beta_{post} = \beta_{prior} + n - y$.

::::: columns
::: {.column width=100%}
```{r}
#| fig-asp: 0.4
#| fig-width: 14
#| fig-align: center
#| out-width: 90%

# Vektor f√ºr pi unter dem Namen ppi bereitstellen
ppi <- seq(from = 0, to = 1, by = 1/1000)
# alpha und beta spezifizieren
a <- 3.5
b <- 27.5
# Dichtevektor
dppi <- dbeta(ppi, shape1 = a, shape2 = b)

mydata <- data.frame(
  ppi = ppi,
  dppi = dppi
)
# Visualisierung 
gf_line(dppi ~ ppi, data = mydata) |>
  gf_labs(x = expression(pi), y = expression(f(pi)), 
          title = "Posteriori-Verteilung",
          subtitle = paste0("Beispiel Beta(", a, ", " , b, ")"))
```
:::
:::::

## Bereichssch√§tzung

```{r}
kred <- 0.8

zi <- qbeta(c((1-kred)/2, 1-(1-kred)/2), a, b)
hi <- HDInterval::hdi(qbeta, kred, shape1 = a,  shape2=b)
```

::::: columns
::: {.column width="50%"}
- Aus der Posteriori-Verteilung k√∂nnen **Kredibilit√§tsintervalle** bestimmt werden.
- Hier erstreckt sich das [**H√∂chste-Dichte-`r kred*100`%**-Kredibilit√§tsintervall]{.green} von $`r round(hi[1],4)`$ bis $`r round(hi[2],4)`$.
- Das entsprechende **symmetrische** Kredibilit√§tsintervall reicht von $`r round(zi[1],4)`$ bis $`r round(zi[2],4)`$ (gestrichelt).
:::

::: {.column width="50%"}
```{r}
#| fig-align: "center"
#| out-width: "90%"

# Visualisierung
gf_line(dppi ~ ppi, data = mydata) |>
  gf_labs(x = expression(pi), y = expression(f(pi)), 
          title = "Posteriori-Verteilung",
          subtitle = paste0("Beispiel Beta(", a, ", " , b, ")")) |>
  gf_lims(x=c(0,0.5)) |>
  gf_vline(xintercept = hi, color = "#00998A") |>
  gf_vline(xintercept = zi, linetype = 2) +
    geom_area(data = subset(mydata,  ppi >= hi[1] & ppi <= hi[2]), 
                  aes(x = ppi, y = dppi), fill = "#00998A", alpha = 0.2)
```
:::
:::::

::: callout-tip
## Tipp

Das H√∂chste-Dichte-Intervall kann z.¬†B. mit Hilfe der Funktion [`hdi()`](https://search.r-project.org/CRAN/refmans/HDInterval/html/hdi.html) aus dem Paket [`HDInterval`](https://cran.r-project.org/package=HDInterval) bestimmt werden, das symmetrische Intervall √ºber [`qbeta()`](https://stat.ethz.ch/R-manual/R-devel/library/stats/html/Beta.html).
:::

## Punktsch√§tzung

```{r}
mw <- a/(a+b) # Mittelwert
mod <- (a-1)/(a+b-2) # Modus
med <- qbeta(0.5, a, b) # Median
```

::::: columns
::: {.column width="50%"}
Die Posteriori-Verteilung kann durch ein Lagema√ü zusammengefasst werden, z.¬†B.:

- [Modus: $`r round(mod,4)`$]{.orange}
- [Median: $`r round(med,4)`$]{.violet}
- [Mittelwert: $`r round(mw,4)`$]{.olive}\
:::

::: {.column width="50%"}
```{r}
#| fig-align: "center"
#| out-width: "90%"

# Visualisierung
gf_line(dppi ~ ppi, data = mydata) |>
  gf_labs(x = expression(pi), y = expression(f(pi)), 
          title = "Posteriori-Verteilung",
          subtitle = paste0("Beispiel Beta(", a, ", " , b, ")")) |>
  gf_vline(xintercept = mw, color = "#808000", size = 1.2) |>
  gf_vline(xintercept = med, color = "#DA70D6", size = 1.2) |>
  gf_vline(xintercept = mod, color = "#FF8811", size = 1.2) |>
  gf_lims(x=c(0,0.5))
```
:::
:::::

::: callout-note
## Hinweis

Modus, Median und Mittelwert beschreiben unterschiedliche Aspekte einer Verteilung und sind je nach Kriterium optimale Zusammenfassungen.
:::

## Schritt: Conclusion - Checkliste

- Checkliste
  - Die Ergebnisse werden klar, neutral und verst√§ndlich kommuniziert. [:ballot_box_with_check:]{.green}
  - Die Schlussfolgerung ist durch die Datenanalyse belegt. [:ballot_box_with_check:]{.green}
  - Die Limitationen der Arbeit sind aufgef√ºhrt. [:ballot_box_with_check:]{.green}

::: callout-tip
## Tipp

Vergleiche *ATOM*: Wasserstein, R. L., Schirm, A. L., & Lazar, N. A. (2019). Moving to a World Beyond ‚Äúp‚Äâ\<‚Äâ0.05.‚Äù *The American Statistician*, *73*(sup1), 1‚Äì19. <https://doi.org/10.1080/00031305.2019.1583913>
:::

## Organisatorisches: Methodische Mindestanforderung

- Priori-Verteilung: Visualisierung
- Likelihood: Visualisierung, Punktsch√§tzer
- Posteriori-Verteilung: Visualisierung, Punktsch√§tzer und Kredibilit√§tsintervall

::: callout-important
## Wichtig

Alle Berechnungen etc. m√ºssen transparent in `Code-Chunks` hinterlegt sein und die Ergebnisse interpretiert werden.
:::

## Organisatorisches: Gruppenarbeiten

- Die Aufgabenstellung und Gliederung sind f√ºr alle Gruppengr√∂√üen gleich. Mit steigender Gruppengr√∂√üe steigt der Umfang der Seminararbeit und die methodischen Mindestanforderungen in der Analyse.
- Individuelle Verantwortung und Bewertung:
  - zu zweit: Likelihood :student:, Posteriori :student:
  - zu dritt: Priori :student:, Likelihood :student:, Posteriori :student:

::: callout-important
## Wichtig

Die individuelle Zuordnung erfolgt anhand der methodischen Prozessschritte innerhalb der Analyse.
:::

## Organisatorisches: Methodische Mindestanforderung Gruppenarbeiten

- **Zus√§tzliche** Mindestanforderungen:
  - Gruppenarbeit zu zweit:
    - Likelihood: Frequentistische Analyse, d.¬†h., Standardfehler, Konfidenzintervall :student:
    - Posteriori: Vorhersagesimulation und Modellcheck :student:
  - Gruppenarbeit zu dritt:
    - Priori: Kennzahlen, Vorhersagesimulation und Modellcheck :student:
    - Likelihood: Frequentistische Analyse, d.¬†h., Standardfehler, Konfidenzintervall :student:
    - Posteriori: Vorhersagesimulation und Modellcheck :student:

::: callout-important
## Wichtig

Die individuellen Verantwortlichkeiten m√ºssen in der Arbeit gekennzeichnet werden.
:::

## Organisatorisches: Bonus :nerd_face:

- Vergleich zweier Anteilswerte (siehe z. B. [`{bayesAB}`](https://cran.r-project.org/package=bayesAB))
- Bayes-Faktoren (siehe z. B. [`{BayesFactor}`](https://cran.r-project.org/package=BayesFactor))
- Sensitivit√§tsanalysen

::: callout-note
## Hinweis

Die sind erg√§nzende **M√∂glichkeiten** f√ºr sehr gute Seminararbeiten, die Sie sich eigenst√§ndig mit Literatur erarbeiten k√∂nnen.
:::

## Ihr Projekt

- Vielleicht ist es m√∂glich, die Seminararbeit zu bestehen, ohne die konzeptionellen Hintergr√ºnde von *Sch√§tzen*, *Bayes*, den Aufbau von `R` oder das Arbeiten mit `Quarto` zu verstehen. :cold_sweat:
- Aber jetzt und sp√§ter: **SIE** profitieren davon, wenn **SIE** begreifen, *was* da *wie* und *warum* passiert. :mortar_board: :money_with_wings:
- Au√üerdem macht es mehr Spa√ü. :smile:
- Nachdenken :thinking:, Nachlesen [:books:]((https://www.bayesrulesbook.com/)) und Nachfragen :raising_hand: k√∂nnen dabei helfen. :innocent:

![](img/Grafiken/T√ºren.jpg){height="400px" fig-align="center"}

# Anhang {#sec-anhang}

## Shiny App

:::: center
<iframe src="https://fomshinyapps.shinyapps.io/BaBeBi/" title width="100%" height="800" style="border:none;">

</iframe>

::: footnote
<https://fomshinyapps.shinyapps.io/BaBeBi/>
:::
::::

## Weitere Literatur (Auswahl)

- Wagenmakers E.-J., & Matzke, D. (2024). *Bayesian inference from the ground up: The theory of common sense*. <https://www.bayesianspectacles.org/free-course-book/>, insbesondere Kapitel 12.
- Albert, J., & Hu, J. (2019). *Probability and Bayesian modeling*. Chapman and Hall/CRC. <https://bayesball.github.io/BOOK/probability-a-measurement-of-uncertainty.html>, insbesondere Kapitel 7.
- Dwney, A.B. (2022). *Think Bayes* (2e). <https://allendowney.github.io/ThinkBayes2/>, insbesondere Kapitel 4.

::: center
:pray: Bitte nennen Sie mir weitere Quellen, die Sie hilfreich finden. :pray:
:::

::: callout-warning
## Warnung

Bei der Problemstellung dieser Seminararbeit sind Sprachmodelle oft fehleranf√§llig.
:::

## Backup: Diskrete Zufallsvariable $X$

- **Verteilungsfunktion**: $$F(x) = Pr(X \leq x) = \sum_{u \leq x} f(u)$$ Wahrscheinlichkeit f√ºr einen Wert kleiner oder gleich $x$.
- **Wahrscheinlichkeitsfunktion**: $$f(x)=Pr(X=x)$$ Wahrscheinlichkeit f√ºr einen Wert gleich $x$.
- **Quantilsfunktion**: $$Q(p)=\inf\{x \in \mathbb{R}: p\geq F(x)\}$$ Kleinster Wert f√ºr $x$, so dass die Wahrscheinlichkeit f√ºr einen Wert kleiner oder gleich $x$ mindestens $p$ betr√§gt.

## Backup: Stetige Zufallsvariable $X$

- **Verteilungsfunktion**: $$F(x) = Pr(X \leq x) = \int_{-\infty}^x f(u)du$$ Wahrscheinlichkeit f√ºr einen Wert kleiner oder gleich $x$.
- **Dichtefunktion**: $$f(x)=F'(x), \text{ wenn } F \text{ differenzierbar ist}$$
- **Quantilsfunktion**: $$Q(p)=\inf\{x \in \mathbb{R}: p\geq F(x)\}$$ Kleinster Wert f√ºr $x$, so dass die Wahrscheinlichkeit f√ºr einen Wert kleiner oder gleich $x$ mindestens $p$ betr√§gt.

## Backup: Konjugierte Priori-Verteilung

- F√ºr binomialverteilte Stichprobendaten ist die Beta-Verteilung die *konjugierte* Priori-Verteilung, d.¬†h., auch die Posteriori-Verteilung ist dann eine Beta-Verteilung. Dies erm√∂glicht eine einfache Berechnung der Posteriori-Verteilung.
- Die Wahl der Priori-Verteilung und der angestrebten Eigenschaften, ob diese z.¬†B. informativ oder nicht-informativ sein soll, ist eine **begr√ºndete** Entscheidung innerhalb der wissenschaftlichen Datenauswertung.

::: callout-important
## Wichtig

Die Priori-Verteilung legen Sie im Schritt **P**lan fest, **bevor** Sie eigene Daten erhoben haben.
:::

## Didaktischer Hintergrund :woman_teacher:

F√ºr den didaktischen Hintergrund siehe z.¬†B.:

- Albert, J. (2000). Using a Sample Survey Project to Assess the Teaching of Statistical Inference. *Journal of Statistics Education*, *8*(1). <https://doi.org/10.1080/10691898.2000.12131283>
- Dogucu, M., Kazak, S., & Rosenberg, J. M. (2024). The Design and Implementation of a Bayesian Data Analysis Lesson for Pre-Service Mathematics and Science Teachers. *Journal of Statistics and Data Science Education*, *33*(2), 177‚Äì188. <https://doi.org/10.1080/26939169.2024.2362148>
- Rosenberg, J.M., Kubsch, M., Wagenmakers, E-J., Dogucu, M. (2022). Making Sense of Uncertainty in the Science Classroom. *Sci & Educ*, *31*, 1239‚Äì1262. <https://doi.org/10.1007/s11191-022-00341-3>
- Wang, F. (2021). Confidence Intervals of COVID-19 Vaccine Efficacy Rates. *Numeracy*, *14*(2). <https://doi.org/10.5038/1936-4660.14.2.1390>
